{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to get residence-time distribution (RTD) for the entire aquifer from an existing MODFLOW model. It is possible to read in any group or label from a 3D array and make RTDs for those groups. The approach is to \n",
    "* read an existing model\n",
    "* create flux-weighted particle starting locations in every cell\n",
    "* run MODPATH and read endpoints\n",
    "* fit parametric distributions\n",
    "\n",
    "This notebook fits parametric distributions. Another notebook creates flux-weighted particles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PFJ updates:\n",
    "\n",
    "1. Process flux and volumetrically-weighted particles at the same time.\n",
    "2. Process all 3 FWP models at the same time\n",
    "3. Plot results of all 6 RTDs on the same graph to generate figure 2 of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'Jeff Starn'\n",
    "%matplotlib notebook\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "from IPython.display import Image\n",
    "from IPython.display import Math\n",
    "from ipywidgets import interact, Dropdown\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import flopy as fp\n",
    "import imeth\n",
    "import fit_parametric_distributions\n",
    "import pandas as pd\n",
    "import gdal\n",
    "import scipy.stats as ss\n",
    "import scipy.optimize as so\n",
    "from scipy.interpolate import Rbf\n",
    "from scipy.interpolate import griddata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set user-defined variables\n",
    "\n",
    "MODFLOW and MODPATH use elapsed time and are not aware of calendar time. To place MODFLOW/MODPATH elapsed time on the calendar, two calendar dates were specified at the top of the notebook: the beginning of the first stress period (`mf_start_date`) and when particles are to be released (`mp_release_date`). The latter date could be used in many ways, for example to represent a sampling date, or it could be looped over to create a time-lapse set of ages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional input by PFJ to run analyses of multiple models:\n",
    "\n",
    "simulate_list = ['FWP1L_zK', 'FWP5L_zK', 'FWP5L_hK']  # list of models in the gen_mod_dict.py file to analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through home directory to get list of name files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "homes = ['../Models']\n",
    "fig_dir = '../Figures'\n",
    "\n",
    "if not os.path.exists(fig_dir):\n",
    "    os.mkdir(fig_dir)  # PFJ:  dst is not defined; changed to fig_dir.\n",
    "\n",
    "mfpth = '../executables/MODFLOW-NWT_1.0.9/bin/MODFLOW-NWT_64.exe'\n",
    "mp_exe_name = '../executables/modpath.6_0/bin/mp6x64.exe' \n",
    "\n",
    "mf_start_date_str = '01/01/1900' \n",
    "mp_release_date_str = '01/01/2017' \n",
    "\n",
    "age_cutoff = 65\n",
    "year_cutoff = '01/01/1952'\n",
    "\n",
    "surf_aq_lays = 3  # deepest layer of the surficial aquifer.\n",
    "\n",
    "dir_list = []\n",
    "mod_list = []\n",
    "i = 0\n",
    "r = 0\n",
    "\n",
    "for home in homes:\n",
    "    if os.path.exists(home):\n",
    "        for dirpath, dirnames, filenames in os.walk(home):\n",
    "            for f in filenames:\n",
    "                if os.path.splitext(f)[-1] == '.nam':\n",
    "                    mod = os.path.splitext(f)[0]\n",
    "                    i += 1\n",
    "                    if mod in simulate_list:\n",
    "                        mod_list.append(mod)\n",
    "                        dir_list.append(dirpath)\n",
    "                        r += 1\n",
    "                               \n",
    "print('    {} models read'.format(i))\n",
    "print('These {} models will be analyzed: {}'.format(r, mod_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create names and path for model workspace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedures in this notebook can be run from the notebook or from a batch file by downloading the notebook as a Python script and uncommenting the following code and commenting out the following block. The remainder of the script has to be indented to be included in the loop.  This may require familiarity with Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# generate list of nam files:\n",
    "nam_list = []\n",
    "for pth in dir_list:\n",
    "    model = os.path.normpath(pth).split(os.sep)[2]\n",
    "    nam_file = '{}.nam'.format(model)\n",
    "    nam_list.append(nam_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load an existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read-in model info and check max/min nlay & create list of DIS objects.  \n",
    "# Assumes all else is the same among models (hnoflow, hdry, etc)\n",
    "print ('Reading model information')\n",
    "nlay_min = 100\n",
    "nlay_max = 0\n",
    "\n",
    "dis_objs = []\n",
    "for i, model in enumerate(nam_list):\n",
    "    nam_file = model\n",
    "    model_ws = dir_list[i]\n",
    "    \n",
    "    fpmg = fp.modflow.Modflow.load(nam_file, model_ws=model_ws, exe_name=mfpth, version='mfnwt', \n",
    "                                   load_only=['DIS', 'BAS6', 'UPW', 'OC'], check=False)\n",
    "\n",
    "    dis = fpmg.get_package('DIS')\n",
    "    dis_objs.append(dis)\n",
    "    bas = fpmg.get_package('BAS6')\n",
    "    upw = fpmg.get_package('UPW')\n",
    "    oc = fpmg.get_package('OC')\n",
    "\n",
    "    delr = dis.delr\n",
    "    delc = dis.delc\n",
    "    nlay = dis.nlay\n",
    "    nrow = dis.nrow\n",
    "    ncol = dis.ncol\n",
    "    bot = dis.getbotm()\n",
    "    top = dis.gettop()\n",
    "\n",
    "    hnoflo = bas.hnoflo\n",
    "    ibound = np.asarray(bas.ibound.get_value())\n",
    "    hdry = upw.hdry\n",
    "    \n",
    "    if nlay > nlay_max:\n",
    "        nlay_max = nlay\n",
    "    if nlay < nlay_min:\n",
    "        nlay_min = nlay\n",
    "        \n",
    "    print('  .. done reading model {}'.format(i+1))\n",
    "\n",
    "print ('   ... all done') \n",
    "\n",
    "print('minimum layers in a model:  {}'.format(nlay_min))\n",
    "print('maximum layers in a model:  {}'.format(nlay_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification of time in MODFLOW/MODPATH\n",
    "\n",
    "There are several time-related concepts used in MODPATH.\n",
    "* `simulation time` is the elapsed time in model time units from the beginning of the first stress period\n",
    "* `reference time` is an arbitrary value of `simulation time` that is between the beginning and ending of `simulation time`\n",
    "* `tracking time` is the elapsed time relative to `reference time`. It is always positive regardless of whether particles are tracked forward or backward\n",
    "* `release time` is when a particle is released and is specified in `tracking time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# setup dictionaries of the MODFLOW units for proper labeling of figures.\n",
    "lenunit = {0:'undefined units', 1:'feet', 2:'meters', 3:'centimeters'}\n",
    "timeunit = {0:'undefined', 1:'second', 2:'minute', 3:'hour', 4:'day', 5:'year'}\n",
    "\n",
    "# Create dictionary of multipliers for converting model time units to days\n",
    "time_dict = dict()\n",
    "time_dict[0] = 1.0 # undefined assumes days, so enter conversion to days\n",
    "time_dict[1] = 24 * 60 * 60\n",
    "time_dict[2] = 24 * 60\n",
    "time_dict[3] = 24\n",
    "time_dict[4] = 1.0\n",
    "time_dict[5] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# convert string representation of dates into Python datetime objects\n",
    "mf_start_date = dt.datetime.strptime(mf_start_date_str , '%m/%d/%Y')\n",
    "mp_release_date = dt.datetime.strptime(mp_release_date_str , '%m/%d/%Y')\n",
    "\n",
    "# convert simulation time to days from the units specified in the MODFLOW DIS file\n",
    "sim_time = np.append(0, dis.get_totim())\n",
    "sim_time /= time_dict[dis.itmuni]\n",
    "\n",
    "# make a list of simulation time formatted as calendar dates\n",
    "date_list = [mf_start_date + dt.timedelta(days = item) for item in sim_time]\n",
    "\n",
    "# reference time and date are set to the end of the last stress period\n",
    "ref_time = sim_time[-1]\n",
    "ref_date = date_list[-1]\n",
    "\n",
    "# release time is calculated in tracking time (for particle release) and \n",
    "# in simulation time (for identifying head and budget components)\n",
    "release_time_trk = np.abs((ref_date - mp_release_date).days)\n",
    "release_time_sim = (mp_release_date - mf_start_date).days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read endpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purge(ep_data):\n",
    "    pre_Quaternary = ep_data.loc[ep_data.rt>=2.6e6]\n",
    "    pre_Cretaceous = ep_data.loc[ep_data.rt>=66e6]\n",
    "    preCambrian = ep_data.loc[ep_data.rt>=541e6]\n",
    "    pre_earth = ep_data.loc[ep_data.rt>=4.6e9]\n",
    "\n",
    "    print('\\nFor your information:')\n",
    "    print('{} particles were simulated as being older than Earth!'.format(preCambrian.shape[0]))\n",
    "    print('{} particles were simulated as being PreCambrian in age.'.format(preCambrian.shape[0]))\n",
    "    print('{} particles were simulated as being Cretaceous in age or older.'.format(pre_Cretaceous.shape[0]))\n",
    "    print('{} particles were simulated as being pre-Quaternary in age.'.format(pre_Quaternary.shape[0]))\n",
    "    \n",
    "    ep_data = ep_data.loc[ep_data.rt<4.6e9]\n",
    "    print('Purged particles older than earth')\n",
    "    return(ep_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Change this block to read-in EPT, save-down pickles of end point file df, and generate CFD plots.  See code block 8 of GM_6flux_scale_analysis.ipynb\n",
    "\n",
    "dfdict = {}\n",
    "for i, model in enumerate(mod_list):\n",
    "    model_ws = dir_list[i]\n",
    "    src = os.path.join(model_ws, 'zone_df.csv')\n",
    "    zone_df = pd.read_csv(src, index_col=0)\n",
    "    dis = dis_objs[i]\n",
    "    for group in zone_df:\n",
    "        print('\\nAnalyzing EPT for {}'.format(model))\n",
    "        \n",
    "        # form the path to the endpoint files\n",
    "        mpname_flux = '{}_flux_{}'.format(os.path.join(model_ws, model), group)\n",
    "        mpname_vol = '{}_volume_{}'.format(os.path.join(model_ws, model), group)\n",
    "        mflux = '{}_flux'.format(model)\n",
    "        mvol = '{}_volume'.format(model)\n",
    "\n",
    "        flux_endpoint_file = '{}.{}'.format(mpname_flux, 'mpend')\n",
    "        vol_endpoint_file = '{}.{}'.format(mpname_vol, 'mpend')\n",
    "\n",
    "        # read the endpoint file to generate a dataframe\n",
    "        f_ep_data1 = fit_parametric_distributions.read_endpoints(flux_endpoint_file, dis, time_dict)\n",
    "        v_ep_data1 = fit_parametric_distributions.read_endpoints(vol_endpoint_file, dis, time_dict)\n",
    "        \n",
    "        f_ep_data = purge(f_ep_data1)\n",
    "        v_ep_data = purge(v_ep_data1)\n",
    "        \n",
    "        fdst = '{}_mod.pickle'.format(os.path.join(mpname_flux))\n",
    "        pickle.dump(f_ep_data, open(fdst, 'wb'))\n",
    "        vdst = '{}_mod.pickle'.format(os.path.join(mpname_vol))\n",
    "        pickle.dump(v_ep_data, open(vdst, 'wb'))\n",
    "        \n",
    "        dfdict[mflux] = f_ep_data\n",
    "        dfdict[mvol] = v_ep_data\n",
    "        \n",
    "print('....done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdict.keys()\n",
    "dfdict['FWP1L_zK_flux'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot CDFs for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot age distributions for all 3 models by flux/vol weight.\n",
    "\n",
    "uniques = dfdict.keys()\n",
    "n_uni = len(uniques)\n",
    "sum_p = {}\n",
    "for mn in uniques:\n",
    "    sum_p[mn] = 0\n",
    "    \n",
    "vplots = 1\n",
    "hplots = 1\n",
    "figsize = (8, 6)\n",
    "CS, ax = plt.subplots(vplots, hplots, figsize=figsize)\n",
    "\n",
    "colors_line = plt.cm.brg(np.linspace(0, 1, len(mod_list)))  # 1 color for each model (3)\n",
    "colors_line = colors_line.repeat(2, axis=0)  # dimensioned to account for flux and vol for each model\n",
    "linestyle = []\n",
    "for i, md in enumerate(uniques):\n",
    "    \n",
    "    if 'flux' in md:\n",
    "        linestyle = '-'\n",
    "    else:\n",
    "        linestyle = '--'\n",
    "        \n",
    "    # keep just particles that started in the surficial aquifer\n",
    "    df = dfdict[md].copy()\n",
    "    df = df[df['Initial Layer'] <= surf_aq_lays]\n",
    "    rt = df.rt.copy()  # 'rt' is \"raw time\" in the dataframe\n",
    "    rt.sort_values(inplace=True)\n",
    "    sum_p[md] = sum_p[md] + rt.count()\n",
    "    y_rt = np.linspace(0, 1, rt.shape[0])\n",
    "\n",
    "    ax.plot(rt, y_rt, c=colors_line[i], linestyle=linestyle, label=md)\n",
    "    ax.plot((65, 65), (0.05, 1), 'k--')\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(1e0, 1e6)\n",
    "    ax.set_ylim(0, )\n",
    "\n",
    "    ax.legend(loc=0, frameon=False, fontsize=8)#, bbox_to_anchor=(0.20, 0.2), ncol=1)\n",
    "    ax.set_xlabel('Residence time, in years')\n",
    "    ax.set_ylabel('Cumulative frequency')\n",
    "\n",
    "CS.subplots_adjust(top= 0.96, hspace=0.15)\n",
    "\n",
    "dst = '../RTD_flux_vs_vol.png'\n",
    "plt.savefig(dst)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc and write-out summary stats for each model and weighting method.\n",
    "dst = '../YFsummary_all_zones.dat'\n",
    "uniques = dfdict.keys()\n",
    "n_uni = len(uniques)\n",
    "    \n",
    "with open(dst, 'w') as f:\n",
    "    for i, md in enumerate(uniques):\n",
    "         # keep just particles that started in the surficial aquifer\n",
    "        df = dfdict[md].copy()\n",
    "        n_part_all = df.shape[0]\n",
    "        medageall = df.rt.median()\n",
    "        df = df[df['Initial Layer'] <= surf_aq_lays]\n",
    "        medageglac = df.rt.median()\n",
    "        n_part_glac = df.shape[0]\n",
    "        young = df[df.rt <= age_cutoff]\n",
    "        yf = young.shape[0] / n_part_glac\n",
    "        meanYFage = young.rt.mean()\n",
    "        medYFage = young.rt.median()\n",
    "        f.write('Summary for {}\\n'.format(md))\n",
    "        f.write('Total particles in model:  {}\\n'.format(n_part_all))\n",
    "        f.write('Total glacial particles:  {}\\n'.format(n_part_glac))\n",
    "        f.write('Median age all particles in model:  {}\\n'.format(medageall))\n",
    "        f.write('Median age all glacial particles:  {}\\n'.format(medageglac))\n",
    "        f.write('Fraction Young glacial particles:  {:.3%}\\n'.format(yf))\n",
    "        f.write('Median age glac YF:  {}\\n'.format(medYFage))\n",
    "        f.write('Mean age glac YF:  {}\\n\\n'.format(meanYFage))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
