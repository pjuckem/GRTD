{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script compares age metrics among models that use uniform versus heterogeneous porosity.  The goal is to evaluate if and how complexity influences age metrics across scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The script reads in the model_grid.csv file for each model and uses that to tie each particle's initial location to select categories, such as the HUC, NLCD, coarse fraction, etc.  The model_grid.csv file was created via verion 2 of the general models / GRTD notebooks, tied to PFJ's repo called \"GenMod\" on the USGS GitLab site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'Paul Juckem'\n",
    "%matplotlib notebook\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "from datetime import datetime\n",
    "import gdal\n",
    "from gdal import ogr, osr\n",
    "import gen_mod_functions as gm\n",
    "import flopy as fp\n",
    "import pickle\n",
    "from ipywidgets import interact, Dropdown, Text\n",
    "from IPython.display import display\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy import stats\n",
    "import csv\n",
    "\n",
    "import fit_parametric_distributions\n",
    "\n",
    "try:\n",
    "    import rasterio\n",
    "except:\n",
    "    print('Install rasterio into your python environment. Or, skip plotting of geotiffs at the end of this notebook')\n",
    "\n",
    "modifier = False\n",
    "def ReturnEntry(sender):\n",
    "    modifier.value = intext.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify user input, including list of models to compare and which axes to plot them, plus attributes to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulate_list = ['FWP1L_zK', 'FWP5L_zK', 'FWP5L_hK']  # list of models (w/ matching directory name) to analyze\n",
    "#compare_list = ('FWP5L_zK', 'FWP5L_hK')  # compare these models directly; both uni_n and het_n versions.  Use a tuple to preserve order\n",
    "evaluate = ('FWP5L_hK', 'FWP5L_zK')  # which two models to compare with color flooding of model factors.  1st minus 2nd, so order matters!\n",
    "abrevdict = {'FWP5L_zK':'5zK', 'FWP5L_hK':'5hK'}\n",
    "\n",
    "# This variable facilitates scenario testing (stopping or not at weak sinks/sources; porosity values & configuration, etc.)\n",
    "#scenario_name = None  # set to None if no additional text was added to the modpath file names.\n",
    "#scenario_name = 'passthroughsnk'  # an optional text string added to MP file names. MUST match value used in NB 01aa!!!\n",
    "scenario_name = 'het_n'  \n",
    "\n",
    "# when comparing results of the scenario to the base case, which weighting option to use? 'flux' or 'volume'\n",
    "base_case = 'flux'\n",
    "\n",
    "# for plotting 1:1 graphs\n",
    "#x1, y1 = 0, 1  # index of names in the yet-to-be-populated eptlist variable.  (0=base case; 1 = scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_aq_lays = 3  # deepest layer of the surficial aquifer.\n",
    "nrow, ncol = 930, 650  # easier to hardcode this than waste the time to read-in a model just to get DIS info.\n",
    "\n",
    "# for labeling RTD plots\n",
    "label_by_model_name = True  # if false, will include zone info in label.\n",
    "\n",
    "category = 'HUC8' \n",
    "age_cutoff = 65\n",
    "minptl = 500  # The minimum number of particles for EACH model within each HUC (eg: if FWP5L has 2000, \n",
    "               # but FWP1L has 800, none get plotted in the 1:1 plots.  Still included in the RTD plots.)\n",
    "               # 500-1000 seems reasonable for 1:1 plots as it includes only HUCs with really refined RTDs;\n",
    "               # however, 100 - 500 seems more reasonable if we want to visualize spatial patterns because it\n",
    "               # allows more HUCs to be plotted.  100-500 is based on visually inspecting RTD curves.\n",
    "                \n",
    "# Columns in the model_grid.csv file to keep.  Purge all others.\n",
    "mg_columns = ['node_num', 'row', 'col', 'HUC6', 'HUC8', 'HUC10', 'HUC12', 'ibound', 'gage_id', 'coarse_flag', \n",
    "              'qu_atlas', 'catchment', 'ssurgo', 'stream_order', 'surfmat']\n",
    "                \n",
    "purge_hucs = [40602, 4060200, 406020000, 40602000000]  # all hucs for Lake Michigan      \n",
    "\n",
    "HUCshpdict = {'HUC6':'E:/HUCS/WBD_4n7/WBD_HUC6_UTMft_FWPdomain.shp', \n",
    "              'HUC8':'E:/HUCS/WBD_4n7/WBD_HUC8_UTMft_FWPdomain.shp', \n",
    "              'HUC10':'E:/HUCS/WBD_4n7/WBD_HUC10_UTMft_FWPdomain.shp', \n",
    "              'HUC12':'E:/HUCS/WBD_4n7/WBD_HUC12_UTMft_FWPdomain.shp'}\n",
    "\n",
    "HUCtiffdict = {'HUC6':'E:/HUCS/WBD_4n7/HUC6_UTMft_FWP.tiff', \n",
    "              'HUC8':'E:/HUCS/WBD_4n7/HUC8_UTMft_FWP.tiff', \n",
    "              'HUC10':'E:/HUCS/WBD_4n7/HUC10_UTMft_FWP.tiff',\n",
    "              'HUC12':'E:/HUCS/WBD_4n7/HUC12_UTMft_FWP.tiff'}\n",
    "\n",
    "dischargerastdict = {'FWP1L_zK': '../TIFFs/FWP1L_zK_SFRgain.tif', 'FWP5L_zK':'../TIFFs/FWP5L_zK_SFRgain.tif', 'FWP5L_hK':\n",
    "                     '../TIFFs/FWP5L_hK_SFRgain.tif'}\n",
    "lossrastdict = {'FWP1L_zK': '../TIFFs/FWP1L_zK_SFRloss.tif', 'FWP5L_zK':'../TIFFs/FWP5L_zK_SFRloss.tif', 'FWP5L_hK':\n",
    "                     '../TIFFs/FWP5L_hK_SFRloss.tif'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep the script for the models to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homes = ['../Models']\n",
    "fig_dir = '../Figures'\n",
    "\n",
    "if not os.path.exists(fig_dir):\n",
    "    os.mkdir(fig_dir)\n",
    "\n",
    "mfpth = '../executables/MODFLOW-NWT_1.0.9/bin/MODFLOW-NWT_64.exe'\n",
    "mp_exe_name = '../executables/modpath.6_0/bin/mp6x64.exe' \n",
    "\n",
    "dir_list = []\n",
    "modlist = []\n",
    "i = 0\n",
    "r = 0\n",
    "\n",
    "path_dict = {}\n",
    "dfdict = {}\n",
    "totp = {}\n",
    "for home in homes:\n",
    "    if os.path.exists(home):\n",
    "        for dirpath, dirnames, filenames in os.walk(home):\n",
    "            for f in filenames:\n",
    "                if os.path.splitext(f)[-1] == '.nam':\n",
    "                    mod = os.path.splitext(f)[0]\n",
    "                    i += 1\n",
    "                    #if mod in compare_list:\n",
    "                    if mod in evaluate:\n",
    "                        modlist.append(mod)\n",
    "                        dir_list.append(dirpath)\n",
    "                        r += 1\n",
    "                        path_dict[mod] = dirpath\n",
    "                               \n",
    "print('    {} models read'.format(i))\n",
    "print('These {} models will be analyzed: {}'.format(r, modlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list of nam files:\n",
    "nam_list = []\n",
    "for pth in dir_list:\n",
    "    model = os.path.normpath(pth).split(os.sep)[2]\n",
    "    nam_file = '{}.nam'.format(model)\n",
    "    nam_list.append(nam_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup dictionaries of the MODFLOW units for proper labeling of figures.\n",
    "lenunit = {0:'undefined units', 1:'feet', 2:'meters', 3:'centimeters'}\n",
    "timeunit = {0:'undefined', 1:'second', 2:'minute', 3:'hour', 4:'day', 5:'year'}\n",
    "\n",
    "# Create dictionary of multipliers for converting model time units to days\n",
    "time_dict = dict()\n",
    "time_dict[0] = 1.0 # undefined assumes days, so enter conversion to days\n",
    "time_dict[1] = 24 * 60 * 60\n",
    "time_dict[2] = 24 * 60\n",
    "time_dict[3] = 24\n",
    "time_dict[4] = 1.0\n",
    "time_dict[5] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read-in model info and check max/min nlay & create list of DIS objects.  \n",
    "# Assumes all else is the same among models (hnoflow, hdry, etc)\n",
    "print ('Reading model information')\n",
    "nlay_min = 100\n",
    "nlay_max = 0\n",
    "\n",
    "dis_objs = []\n",
    "for i, model in enumerate(nam_list):\n",
    "    nam_file = model\n",
    "    model_ws = dir_list[i]\n",
    "    \n",
    "    fpmg = fp.modflow.Modflow.load(nam_file, model_ws=model_ws, exe_name=mfpth, version='mfnwt', \n",
    "                                   load_only=['DIS', 'BAS6', 'UPW', 'OC'], check=False)\n",
    "\n",
    "    dis = fpmg.get_package('DIS')\n",
    "    dis_objs.append(dis)\n",
    "    bas = fpmg.get_package('BAS6')\n",
    "    upw = fpmg.get_package('UPW')\n",
    "    oc = fpmg.get_package('OC')\n",
    "\n",
    "    delr = dis.delr\n",
    "    delc = dis.delc\n",
    "    nlay = dis.nlay\n",
    "    nrow = dis.nrow\n",
    "    ncol = dis.ncol\n",
    "    bot = dis.getbotm()\n",
    "    top = dis.gettop()\n",
    "\n",
    "    hnoflo = bas.hnoflo\n",
    "    ibound = np.asarray(bas.ibound.get_value())\n",
    "    hdry = upw.hdry\n",
    "    \n",
    "    if nlay > nlay_max:\n",
    "        nlay_max = nlay\n",
    "    if nlay < nlay_min:\n",
    "        nlay_min = nlay\n",
    "        \n",
    "    print('  .. done reading model {}'.format(i+1))\n",
    "\n",
    "print ('   ... all done') \n",
    "\n",
    "print('minimum layers in a model:  {}'.format(nlay_min))\n",
    "print('maximum layers in a model:  {}'.format(nlay_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process endpoint files and merge with model_grid.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purge(ep_data):\n",
    "    pre_Quaternary = ep_data.loc[ep_data.rt>=2.6e6]\n",
    "    pre_Cretaceous = ep_data.loc[ep_data.rt>=66e6]\n",
    "    preCambrian = ep_data.loc[ep_data.rt>=541e6]\n",
    "    pre_earth = ep_data.loc[ep_data.rt>=4.6e9]\n",
    "\n",
    "    print('\\nFor your information:')\n",
    "    print('{} particles were simulated as being older than Earth!'.format(preCambrian.shape[0]))\n",
    "    print('{} particles were simulated as being PreCambrian in age.'.format(preCambrian.shape[0]))\n",
    "    print('{} particles were simulated as being Cretaceous in age or older.'.format(pre_Cretaceous.shape[0]))\n",
    "    print('{} particles were simulated as being pre-Quaternary in age.'.format(pre_Quaternary.shape[0]))\n",
    "    \n",
    "    ep_data = ep_data.loc[ep_data.rt<4.6e9]\n",
    "    print('Purged particles older than earth')\n",
    "    return(ep_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read-in the model_grid.csv file for each model.  Then create a dataframe from each csv & pickle file.\n",
    "\n",
    "dfdict = {}\n",
    "totp = {}\n",
    "\n",
    "for i, model in enumerate(evaluate):\n",
    "#for i, model in enumerate(compare_list):\n",
    "    g = os.path.join(path_dict[model], 'model_grid.csv')\n",
    "    z = os.path.join(path_dict[model], 'zone_df.csv')\n",
    "    try:\n",
    "        df = pd.read_csv(g)\n",
    "        df.ibound.replace(0, np.nan, inplace=True)\n",
    "        df = df[df.ibound.notnull()]\n",
    "        df = df[mg_columns]  # keep just the desired fields\n",
    "        # re-calculate 2D cell number b/c node_num is computed differently for model_grid.csv and what's in the ept file.\n",
    "        df['cellnum2d'] = df.row * ncol + df.col\n",
    "        \n",
    "        zone_df = pd.read_csv(z, index_col=0)\n",
    "        for group in zone_df:\n",
    "            print('\\nReading-in the EPT file for {} in {}'.format(group, model))\n",
    "            if scenario_name == None:\n",
    "                print(\"Oops, I didn't really plan for this.  Stopping\")\n",
    "                sys.exit()\n",
    "            else:\n",
    "                p1 = os.path.join(path_dict[model], '{}_{}_{}.mpend'.format(model, base_case, group))\n",
    "                p2 = os.path.join(path_dict[model], '{}_{}_{}_{}.mpend'.format(model, base_case, group, scenario_name))\n",
    "                mnz1 = '{}_{}'.format(model, group)\n",
    "                mnz2 = '{}_{}_{}'.format(model, group, scenario_name)\n",
    "                eptu1 = fit_parametric_distributions.read_endpoints(p1, dis, time_dict)\n",
    "                eptu2 = fit_parametric_distributions.read_endpoints(p2, dis, time_dict)\n",
    "                \n",
    "            eptu1 = purge(eptu1)\n",
    "            eptu2 = purge(eptu2)\n",
    "            eptu1['cellnum2d'] = (eptu1['Initial Row']-1) * ncol + (eptu1['Initial Column'] -1)  # -1 to convert to 0-based\n",
    "            eptu2['cellnum2d'] = (eptu2['Initial Row']-1) * ncol + (eptu2['Initial Column'] -1)  # -1 to convert to 0-based\n",
    "            eptu1_mg = eptu1.join(df, on='cellnum2d', lsuffix='_ept', rsuffix='_mg')\n",
    "            eptu2_mg = eptu2.join(df, on='cellnum2d', lsuffix='_ept', rsuffix='_mg')\n",
    "            eptu1_mg = eptu1_mg[eptu1_mg['Initial Layer'] <= surf_aq_lays]  # ensure that we're only analyzing Glacial!\n",
    "            eptu2_mg = eptu2_mg[eptu2_mg['Initial Layer'] <= surf_aq_lays]  # ensure that we're only analyzing Glacial!\n",
    "\n",
    "            #dfdict[model] = eptu_mg\n",
    "            dfdict[mnz1] = eptu1_mg\n",
    "            dfdict[mnz2] = eptu2_mg\n",
    "            totp[mnz1] = eptu1_mg.rt.count()\n",
    "            totp[mnz2] = eptu2_mg.rt.count()\n",
    "            \n",
    "            #x1 = eptlist[x1]  # pull out the file name after supplying the index\n",
    "            #y1 = eptlist[y1]\n",
    "            \n",
    "    except (AttributeError, ValueError, IOError, IndexError):\n",
    "        print('ERROR. THIS CODE BLOCK DID NOT COMPLETE. TROUBLE-SHOOT AND TRY AGAIN')\n",
    "        print('The error occured while working on this model: {}'.format(model))\n",
    "        raise SystemExit()\n",
    "\n",
    "eptlist = list(dfdict.keys())\n",
    "print('....done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eptlist)\n",
    "print(modlist)  # can't control the order of this one\n",
    "print(evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot age distributions for uniform and heterogeneous porosity models by selected HUC\n",
    "\n",
    "uniques = dfdict[eptlist[0]][category].unique()\n",
    "# remove any HUCs listed in purge_hucs\n",
    "for h in purge_hucs:\n",
    "    ind = np.where(uniques==h)\n",
    "    uniques = np.delete(uniques, ind)\n",
    "\n",
    "n_uni = len(uniques)\n",
    "sum_p = {}\n",
    "for mn in eptlist:\n",
    "    sum_p[mn] = 0\n",
    "    \n",
    "if n_uni <= 20:\n",
    "    vplots = int(np.ceil(n_uni/ 3.0))\n",
    "    figsize = (12, 3*vplots)\n",
    "    CS, CSaxes = plt.subplots(vplots, 3, figsize=figsize)\n",
    "else:\n",
    "    hplots = int(np.round(np.sqrt(n_uni)))\n",
    "    vplots = int(np.ceil(np.sqrt(n_uni)))\n",
    "    figsize = (hplots*4, hplots*3)\n",
    "    CS, CSaxes = plt.subplots(vplots, hplots, figsize=figsize)\n",
    "        \n",
    "colors_line = plt.cm.brg(np.linspace(0, 1, len(eptlist)))\n",
    "\n",
    "for ax, cat_val in zip(CSaxes.flat, uniques):\n",
    "    n = []\n",
    "    for i, md in enumerate(eptlist):\n",
    "        rt = dfdict[md].loc[dfdict[md][category]==cat_val, 'rt']  # 'rt' is \"raw time\" in the dataframe\n",
    "        rt.sort_values(inplace=True)\n",
    "        n.append(rt.count())\n",
    "        sum_p[md] = sum_p[md] + rt.count()\n",
    "        y_rt = np.linspace(0, 1, rt.shape[0])\n",
    "    \n",
    "        if label_by_model_name:\n",
    "            label = eptlist[i]\n",
    "        else:\n",
    "            label = md\n",
    "        ax.plot(rt, y_rt, c=colors_line[i], label=label)\n",
    "        ax.plot((age_cutoff, age_cutoff), (0.2, 1), 'k--')\n",
    "        \n",
    "        title = '{}: {}'.format(category, cat_val)\n",
    "        ax.set_title(title, fontsize=12)\n",
    "\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlim(1e0, 1e3)\n",
    "        ax.set_ylim(0, )\n",
    "\n",
    "        ax.legend(loc=0, frameon=False, fontsize=8)#, bbox_to_anchor=(0.20, 0.2), ncol=1)\n",
    "        ax.set_xlabel('Residence time, in years')\n",
    "        ax.set_ylabel('Cumulative frequency')\n",
    "        if len(n) == len(modlist):\n",
    "            nmin, nmax = min(n), max(n)\n",
    "            ax.text(5,0.02, '# particles: {:,} - {:,}'.format(nmin, nmax))\n",
    "        \n",
    "CS.suptitle('Comparison of glacial particle time distributions by {} for FWP scenarios'.format(category), fontsize=18)  \n",
    "CS.tight_layout()\n",
    "\n",
    "if n_uni < 18:\n",
    "    #CS.subplots_adjust(top= 0.86, hspace=0.85)\n",
    "    CS.subplots_adjust(top= 0.86)\n",
    "elif n_uni < 100:\n",
    "    CS.subplots_adjust(top= 0.93, hspace=0.55)\n",
    "elif n_uni < 400:\n",
    "    CS.subplots_adjust(top= 0.95, hspace=0.55)\n",
    "else:\n",
    "    CS.subplots_adjust(top= 0.97, hspace=0.55)\n",
    "\n",
    "#dst = 'RTD_compare--{}_{}'.format(category, scenario_name)\n",
    "#dst_pth = os.path.join(fig_dir, dst)\n",
    "#plt.savefig(dst_pth)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 plot of Young Fraction for uniform (X) versus heterogeneous (Y) porosity models by selected HUC\n",
    "\n",
    "x1, y1, x2, y2 = eptlist[2], eptlist[3], eptlist[0], eptlist[1]  # columns in eptlist. In this case (x=uniform n; y = hetero n)\n",
    "\n",
    "uniques = dfdict[eptlist[0]][category].unique()\n",
    "# remove any HUCs listed in purge_hucs\n",
    "for h in purge_hucs:\n",
    "    ind = np.where(uniques==h)\n",
    "    uniques = np.delete(uniques, ind)\n",
    "\n",
    "yfhucdict = {}\n",
    "yfvalues = []\n",
    "skiphuc = []\n",
    "for j, cat_val in enumerate(uniques):  # each HUC ID\n",
    "    yfmoddict = {}\n",
    "    for i, md in enumerate(eptlist):  # each of the 3 FWP models\n",
    "        mn = eptlist[i]\n",
    "        df = dfdict[md][dfdict[md][category]==cat_val].copy()\n",
    "        if df.rt.count() >= minptl:\n",
    "            youngdf = df.loc[df.rt < age_cutoff]\n",
    "            yf = youngdf.rt.count() / df.rt.count()\n",
    "            yfmoddict[mn] = yf\n",
    "            yfvalues.append(yf)\n",
    "        else:\n",
    "            skiphuc.append(cat_val)\n",
    "            break\n",
    "    if cat_val not in skiphuc:\n",
    "        yfhucdict[cat_val] = yfmoddict    \n",
    "        \n",
    "ddd = pd.DataFrame(yfhucdict).T\n",
    "Prho_y1, Pp_y1 = stats.pearsonr(np.array(ddd[x1]), np.array(ddd[y1]))\n",
    "Srho_y1, Sp_y1 = stats.spearmanr(np.array(ddd[x1]), np.array(ddd[y1]))\n",
    "std_y1 = stats.tstd(np.array(ddd[x1]) - np.array(ddd[y1]))\n",
    "ME_y1 = np.mean(np.array(ddd[x1]) - np.array(ddd[y1]))\n",
    "Prho_y2, Pp_y2 = stats.pearsonr(np.array(ddd[x2]), np.array(ddd[y2]))\n",
    "Srho_y2, Sp_y2 = stats.spearmanr(np.array(ddd[x2]), np.array(ddd[y2]))\n",
    "std_y2 = stats.tstd(np.array(ddd[x2]) - np.array(ddd[y2]))\n",
    "ME_y2 = np.mean(np.array(ddd[x2]) - np.array(ddd[y2]))\n",
    "\n",
    "#plotting\n",
    "mini = min(min(ddd[x1]), min(ddd[x2]), min(ddd[y1]), min(ddd[y2]))\n",
    "maxi = max(max(ddd[x1]), max(ddd[x2]), max(ddd[y1]), max(ddd[y2]))\n",
    "yrange = maxi-mini\n",
    "ax = ddd.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', label='{}: uniform n vs heterogeneous n'.format(evaluate[1]))\n",
    "ddd.plot(kind='scatter', x=x2, y=y2, marker='^', color='blue', label = '{}: uniform n vs heterogeneous n'.format(evaluate[0]), ax=ax)\n",
    "lowlim = min(ax.get_xlim()[0], ax.get_ylim()[0])\n",
    "uplim = max(ax.get_xlim()[1], ax.get_ylim()[1])\n",
    "lims = (lowlim, uplim)\n",
    "lrange = uplim - lowlim\n",
    "ax.set_xlim(lims)  # force the plots to be square\n",
    "ax.set_ylim(lims)\n",
    "ax.plot((mini, maxi), (mini, maxi), 'k--')\n",
    "\n",
    "plt.xlabel('Young Fraction from the uniform porosity models')\n",
    "plt.ylabel('Young Fraction from the heterogeneous porosity models')\n",
    "plt.suptitle('Comparison of glacial Young Fraction\\n due to heterogeneous porosity, by {}'.format(category), fontsize=14)\n",
    "#ax.text(0.76, maxi, 'R2 = {:3.3f}'.format(r2_y1), fontsize=9, color='green')\n",
    "#ax.text(0.76, maxi-0.02, 'R2 = {:3.3f}'.format(r2_y2), fontsize=9, color='blue')\n",
    "ax.text(lowlim+0.03*lrange, uplim-0.06*lrange, r'$r_p$ = {:3.3f}'.format(Prho_y1), fontsize=9, color='green')\n",
    "ax.text(lowlim+0.03*lrange, uplim-0.11*lrange, r'$r_s$ = {:3.3f}'.format(Srho_y1), fontsize=9, color='green')\n",
    "ax.text(lowlim+0.03*lrange, uplim-0.16*lrange, r'$std$ = {:3.3f}'.format(std_y1), fontsize=9, color='green')\n",
    "ax.text(lowlim+0.03*lrange, uplim-0.21*lrange, r'$ME$ = {:3.3f}'.format(ME_y1), fontsize=9, color='green')\n",
    "ax.text(lowlim+0.03*lrange, uplim-0.26*lrange, r'$r_p$ = {:3.3f}'.format(Prho_y2), fontsize=9, color='blue')\n",
    "ax.text(lowlim+0.03*lrange, uplim-0.31*lrange, r'$r_s$ = {:3.3f}'.format(Srho_y2), fontsize=9, color='blue')\n",
    "ax.text(lowlim+0.03*lrange, uplim-0.36*lrange, r'$std$ = {:3.3f}'.format(std_y2), fontsize=9, color='blue')\n",
    "ax.text(lowlim+0.03*lrange, uplim-0.41*lrange, r'$ME$ = {:3.3f}'.format(ME_y2), fontsize=9, color='blue')\n",
    "#plt.tight_layout()\n",
    "\n",
    "dst = 'YFrac_121_compare_heteroN_{}'.format(category)\n",
    "dst_pth = os.path.join(fig_dir, dst)\n",
    "plt.savefig(dst_pth)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 plot of Young Fraction for uniform (X) versus heterogeneous (Y) porosity for ALL HUC scales.\n",
    "\n",
    "x1, y1, x2, y2 = eptlist[2], eptlist[3], eptlist[0], eptlist[1]  # columns in eptlist. In this case (x=uniform n; y = hetero n)\n",
    "hucs = ['HUC6', 'HUC8', 'HUC10', 'HUC12']\n",
    "nhucs = len(hucs)\n",
    "fig, [[ax1, ax2], [ax3, ax4]] = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "axisdict = {0:ax1, 1:ax2, 2:ax3, 3:ax4}\n",
    "\n",
    "for k, each in enumerate(hucs):\n",
    "    # make sure we get ALL unique HUC IDs\n",
    "    u1 = dfdict[eptlist[0]][each].unique()\n",
    "    u2 = dfdict[eptlist[2]][each].unique()\n",
    "    u = np.append(u1, u2)\n",
    "    uniques = np.unique(u)\n",
    "    # remove any HUCs listed in purge_hucs\n",
    "    for h in purge_hucs:\n",
    "        ind = np.where(uniques==h)\n",
    "        uniques = np.delete(uniques, ind)\n",
    "    axis = axisdict[k]\n",
    "\n",
    "    yfhucdict = {}\n",
    "    yfvalues = []\n",
    "    skiphuc = []\n",
    "    for j, cat_val in enumerate(uniques):  # each HUC ID\n",
    "        yfmoddict = {}\n",
    "        for i, md in enumerate(eptlist):  # each of the 3 FWP models\n",
    "            mn = eptlist[i]\n",
    "            df = dfdict[md].loc[dfdict[md][each]==cat_val]\n",
    "            if df.rt.count() >= minptl:\n",
    "                youngdf = df.loc[df.rt < age_cutoff]\n",
    "                yf = youngdf.rt.count() / df.rt.count()\n",
    "                yfmoddict[mn] = yf\n",
    "                yfvalues.append(yf)\n",
    "            else:\n",
    "                skiphuc.append(cat_val)\n",
    "                break\n",
    "        if cat_val not in skiphuc:\n",
    "            yfhucdict[cat_val] = yfmoddict    \n",
    "\n",
    "    ddd = pd.DataFrame(yfhucdict).T\n",
    "    Prho_y1, Pp_y1 = stats.pearsonr(np.array(ddd[x1]), np.array(ddd[y1]))\n",
    "    Srho_y1, Sp_y1 = stats.spearmanr(np.array(ddd[x1]), np.array(ddd[y1]))\n",
    "    std_y1 = stats.tstd(np.array(ddd[x1]) - np.array(ddd[y1]))\n",
    "    ME_y1 = np.mean(np.array(ddd[x1]) - np.array(ddd[y1]))\n",
    "    Prho_y2, Pp_y2 = stats.pearsonr(np.array(ddd[x2]), np.array(ddd[y2]))\n",
    "    Srho_y2, Sp_y2 = stats.spearmanr(np.array(ddd[x2]), np.array(ddd[y2]))\n",
    "    std_y2 = stats.tstd(np.array(ddd[x2]) - np.array(ddd[y2]))\n",
    "    ME_y2 = np.mean(np.array(ddd[x2]) - np.array(ddd[y2]))\n",
    "    \n",
    "    #plotting\n",
    "    mini = min(min(ddd[x1]), min(ddd[x2]), min(ddd[y1]), min(ddd[y2]))\n",
    "    maxi = max(max(ddd[x1]), max(ddd[x2]), max(ddd[y1]), max(ddd[y2]))\n",
    "    yrange = maxi-mini\n",
    "    if k == 0:\n",
    "        ddd.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', label='{}: uniform n vs heterogeneous n'.format(evaluate[1]), ax=axis)\n",
    "        ddd.plot(kind='scatter', x=x2, y=y2, marker='^', color='blue', label = '{}: uniform n vs heterogeneous n'.format(evaluate[0]), ax=axis)\n",
    "        axis.text(mini, mini+0.83*yrange, r'$r_p$ = {:3.3f}'.format(Prho_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.78*yrange, r'$r_s$ = {:3.3f}'.format(Srho_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.73*yrange, r'$std$ = {:3.3f}'.format(std_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.68*yrange, r'$ME$ = {:3.3f}'.format(ME_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.63*yrange, r'$r_p$ = {:3.3f}'.format(Prho_y2), fontsize=9, color='blue')\n",
    "        axis.text(mini, mini+0.58*yrange, r'$r_s$ = {:3.3f}'.format(Srho_y2), fontsize=9, color='blue')\n",
    "        axis.text(mini, mini+0.53*yrange, r'$std$ = {:3.3f}'.format(std_y2), fontsize=9, color='blue')\n",
    "        axis.text(mini, mini+0.48*yrange, r'$ME$ = {:3.3f}'.format(ME_y2), fontsize=9, color='blue')\n",
    "    else:\n",
    "        ddd.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', ax=axis)\n",
    "        ddd.plot(kind='scatter', x=x2, y=y2, marker='^', color='blue', ax=axis)\n",
    "        axis.text(mini, mini+yrange, r'$r_p$ = {:3.3f}'.format(Prho_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.95*yrange, r'$r_s$ = {:3.3f}'.format(Srho_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.90*yrange, r'$std$ = {:3.3f}'.format(std_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.85*yrange, r'$ME$ = {:3.3f}'.format(ME_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.80*yrange, r'$r_p$ = {:3.3f}'.format(Prho_y2), fontsize=9, color='blue')\n",
    "        axis.text(mini, mini+0.75*yrange, r'$r_s$ = {:3.3f}'.format(Srho_y2), fontsize=9, color='blue')\n",
    "        axis.text(mini, mini+0.70*yrange, r'$std$ = {:3.3f}'.format(std_y2), fontsize=9, color='blue')\n",
    "        axis.text(mini, mini+0.65*yrange, r'$ME$ = {:3.3f}'.format(ME_y2), fontsize=9, color='blue')    \n",
    "    \n",
    "    axis.plot((mini, maxi), (mini, maxi), 'k--')\n",
    "    axis.set_xlabel(''), axis.set_ylabel('')\n",
    "    axis.set_title(each)\n",
    "    \n",
    "    # Add an attribute to the HUC shapefile\n",
    "    shapefile = HUCshpdict[each]\n",
    "    shp = gpd.read_file(shapefile)  \n",
    "    shp[each] = shp[each].astype('int64')  # convert so can merge\n",
    "    ddd.index = ddd.index.astype('int64')  # convert so can merge\n",
    "    ddd['YF_zK_uniVShet_n'.format(scenario_name, base_case)] = ddd[x1] - ddd[y1]\n",
    "    ddd['YF_hK_uniVShet_n'.format(scenario_name, base_case)] = ddd[x2] - ddd[y2]\n",
    "\n",
    "    df = pd.merge(shp, ddd, how='outer', left_on=each, right_index=True)\n",
    "    dst = shapefile[:-4] + '_YF_{}.shp'.format(scenario_name)\n",
    "    df.to_file(dst)\n",
    "\n",
    "fig.text(0.5, 0.06, 'Young Fraction from the uniform porosity models', ha='center')\n",
    "fig.text(0.06, 0.48, 'Young Fraction from the heterogeneous porosity models', va='center', rotation='vertical')\n",
    "plt.subplots_adjust(top = .9)\n",
    "fig.suptitle('Comparison of glacial aquifer Young Fractions\\n by HUCs: uniform vs heterogeneous porosity.', fontsize=14)\n",
    "\n",
    "dst = 'YFrac_121_uniVShet_n_allHUCS'\n",
    "dst_pth = os.path.join(fig_dir, dst)\n",
    "plt.savefig(dst_pth)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eptlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 plot of Young Fraction for complexe (X) versus simple (Y)  MF models for uniform and heterogeneous porosities for all HUC scales\n",
    "\n",
    "# That is, we're testing to see if adding heterogeneous porosity increases or decreases the mis-match between simple and complexe MF models.\n",
    "# If rho, std, & ME all improve or degrade, then that may indicate if age metrics from simple MF models can be improved by using texture to inform porosity.\n",
    "\n",
    "x1, y1, x2, y2 = eptlist[0], eptlist[2], eptlist[1], eptlist[3]  # columns in eptlist. In this case (x=complexe MF; y=simple MF)\n",
    "hucs = ['HUC6', 'HUC8', 'HUC10', 'HUC12']\n",
    "nhucs = len(hucs)\n",
    "fig, [[ax1, ax2], [ax3, ax4]] = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "axisdict = {0:ax1, 1:ax2, 2:ax3, 3:ax4}\n",
    "\n",
    "for k, each in enumerate(hucs):\n",
    "    # make sure we get ALL unique HUC IDs\n",
    "    u1 = dfdict[eptlist[0]][each].unique()\n",
    "    u2 = dfdict[eptlist[2]][each].unique()\n",
    "    u = np.append(u1, u2)\n",
    "    uniques = np.unique(u)\n",
    "    # remove any HUCs listed in purge_hucs\n",
    "    for h in purge_hucs:\n",
    "        ind = np.where(uniques==h)\n",
    "        uniques = np.delete(uniques, ind)\n",
    "    axis = axisdict[k]\n",
    "\n",
    "    yfhucdict = {}\n",
    "    yfvalues = []\n",
    "    skiphuc = []\n",
    "    for j, cat_val in enumerate(uniques):  # each HUC ID\n",
    "        yfmoddict = {}\n",
    "        for i, md in enumerate(eptlist):  # each of the 3 FWP models\n",
    "            mn = eptlist[i]\n",
    "            df = dfdict[md].loc[dfdict[md][each]==cat_val]\n",
    "            if df.rt.count() >= minptl:\n",
    "                youngdf = df.loc[df.rt < age_cutoff]\n",
    "                yf = youngdf.rt.count() / df.rt.count()\n",
    "                yfmoddict[mn] = yf\n",
    "                yfvalues.append(yf)\n",
    "            else:\n",
    "                skiphuc.append(cat_val)\n",
    "                break\n",
    "        if cat_val not in skiphuc:\n",
    "            yfhucdict[cat_val] = yfmoddict    \n",
    "\n",
    "    ddd = pd.DataFrame(yfhucdict).T\n",
    "    Prho_y1, Pp_y1 = stats.pearsonr(np.array(ddd[x1]), np.array(ddd[y1]))\n",
    "    Srho_y1, Sp_y1 = stats.spearmanr(np.array(ddd[x1]), np.array(ddd[y1]))\n",
    "    std_y1 = stats.tstd(np.array(ddd[x1]) - np.array(ddd[y1]))\n",
    "    ME_y1 = np.mean(np.array(ddd[x1]) - np.array(ddd[y1]))\n",
    "    Prho_y2, Pp_y2 = stats.pearsonr(np.array(ddd[x2]), np.array(ddd[y2]))\n",
    "    Srho_y2, Sp_y2 = stats.spearmanr(np.array(ddd[x2]), np.array(ddd[y2]))\n",
    "    std_y2 = stats.tstd(np.array(ddd[x2]) - np.array(ddd[y2]))\n",
    "    ME_y2 = np.mean(np.array(ddd[x2]) - np.array(ddd[y2]))\n",
    "    \n",
    "    #plotting\n",
    "    mini = min(min(ddd[x1]), min(ddd[x2]), min(ddd[y1]), min(ddd[y2]))\n",
    "    maxi = max(max(ddd[x1]), max(ddd[x2]), max(ddd[y1]), max(ddd[y2]))\n",
    "    yrange = maxi-mini\n",
    "    if k == 0:\n",
    "        ddd.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', label='uniform n: hetero. K vs zoned K', ax=axis)\n",
    "        ddd.plot(kind='scatter', x=x2, y=y2, marker='^', color='blue', label = 'hetero. n: hetero. K vs zoned K', ax=axis)\n",
    "        axis.text(mini, mini+0.83*yrange, r'$r_p$ = {:3.3f}'.format(Prho_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.78*yrange, r'$r_s$ = {:3.3f}'.format(Srho_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.73*yrange, r'$std$ = {:3.3f}'.format(std_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.68*yrange, r'$ME$ = {:3.3f}'.format(ME_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.63*yrange, r'$r_p$ = {:3.3f}'.format(Prho_y2), fontsize=9, color='blue')\n",
    "        axis.text(mini, mini+0.58*yrange, r'$r_s$ = {:3.3f}'.format(Srho_y2), fontsize=9, color='blue')\n",
    "        axis.text(mini, mini+0.53*yrange, r'$std$ = {:3.3f}'.format(std_y2), fontsize=9, color='blue')\n",
    "        axis.text(mini, mini+0.48*yrange, r'$ME$ = {:3.3f}'.format(ME_y2), fontsize=9, color='blue')\n",
    "    else:\n",
    "        ddd.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', ax=axis)\n",
    "        ddd.plot(kind='scatter', x=x2, y=y2, marker='^', color='blue', ax=axis)\n",
    "        axis.text(mini, mini+yrange, r'$r_p$ = {:3.3f}'.format(Prho_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.95*yrange, r'$r_s$ = {:3.3f}'.format(Srho_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.90*yrange, r'$std$ = {:3.3f}'.format(std_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.85*yrange, r'$ME$ = {:3.3f}'.format(ME_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.80*yrange, r'$r_p$ = {:3.3f}'.format(Prho_y2), fontsize=9, color='blue')\n",
    "        axis.text(mini, mini+0.75*yrange, r'$r_s$ = {:3.3f}'.format(Srho_y2), fontsize=9, color='blue')\n",
    "        axis.text(mini, mini+0.70*yrange, r'$std$ = {:3.3f}'.format(std_y2), fontsize=9, color='blue')\n",
    "        axis.text(mini, mini+0.65*yrange, r'$ME$ = {:3.3f}'.format(ME_y2), fontsize=9, color='blue')    \n",
    "    \n",
    "    axis.plot((mini, maxi), (mini, maxi), 'k--')\n",
    "    axis.set_xlabel(''), axis.set_ylabel('')\n",
    "    axis.set_title(each)\n",
    "    \n",
    "    # Add an attribute to the HUC shapefile\n",
    "    shapefile = HUCshpdict[each]\n",
    "    shp = gpd.read_file(shapefile)  \n",
    "    shp[each] = shp[each].astype('int64')  # convert so can merge\n",
    "    ddd.index = ddd.index.astype('int64')  # convert so can merge\n",
    "    #ddd['YF_zK_uniVShet_n'.format(scenario_name, base_case)] = ddd[x1] - ddd[y1]\n",
    "    ddd['YF_{}_hK2zK'.format(scenario_name)] = ddd[x2] - ddd[y2]\n",
    "\n",
    "    df = pd.merge(shp, ddd, how='outer', left_on=each, right_index=True)\n",
    "    dst = shapefile[:-4] + '_YF_{}_hK2zK.shp'.format(scenario_name)\n",
    "    df.to_file(dst)\n",
    "\n",
    "fig.text(0.5, 0.06, 'Young Fraction from the heterogeneous K Modflow models', ha='center')\n",
    "fig.text(0.06, 0.48, 'Young Fraction from the zoned K Modflow models', va='center', rotation='vertical')\n",
    "plt.subplots_adjust(top = .9)\n",
    "fig.suptitle('Comparison of glacial aquifer Young Fractions\\n by HUCs: heterogeneous vs zoned K.', fontsize=14)\n",
    "\n",
    "dst = 'YFrac_121_hetn_hK2zK_allHUCS'\n",
    "dst_pth = os.path.join(fig_dir, dst)\n",
    "plt.savefig(dst_pth)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 plot of median-YF-age and mOFage for complexe (X) versus simple (Y) MF models for uniform and heterogeneous porosities \n",
    "# for the select scale.\n",
    "\n",
    "# That is, does adding heterogeneous porosity also improve median ages as it did with YF calculations for simple and complex\n",
    "# MF models?\n",
    "\n",
    "x1, y1, x2, y2 = eptlist[0], eptlist[2], eptlist[1], eptlist[3]  # columns in eptlist. In this case (x=complexe MF; y=simple MF)\n",
    "\n",
    "# make sure we get ALL unique HUC IDs\n",
    "u1 = dfdict[eptlist[0]][category].unique()\n",
    "u2 = dfdict[eptlist[1]][category].unique()\n",
    "u = np.append(u1, u2)\n",
    "uniques = np.unique(u)\n",
    "# remove any HUCs listed in purge_hucs\n",
    "for h in purge_hucs:\n",
    "    ind = np.where(uniques==h)\n",
    "    uniques = np.delete(uniques, ind)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10, 4.6))\n",
    "\n",
    "skiphuc = []\n",
    "yfhucdict = {}\n",
    "yfvalues = []\n",
    "ofhucdict = {}\n",
    "ofvalues = []\n",
    "for j, cat_val in enumerate(uniques):  # each HUC ID\n",
    "    yfmoddict = {}\n",
    "    ofmoddict = {}\n",
    "    for i, md in enumerate(eptlist):  # each of the 3 FWP models\n",
    "        mn = eptlist[i]\n",
    "        df = dfdict[md].loc[dfdict[md][category]==cat_val]\n",
    "        if df.rt.count() >= minptl:\n",
    "            youngdf = df.loc[df.rt < age_cutoff]\n",
    "            olddf = df.loc[df.rt >= age_cutoff]\n",
    "            yfage = youngdf.rt.median()\n",
    "            ofage = olddf.rt.median()\n",
    "            yfmoddict[mn] = yfage\n",
    "            yfvalues.append(yfage) \n",
    "            ofmoddict[mn] = ofage\n",
    "            ofvalues.append(ofage)\n",
    "        else:\n",
    "            skiphuc.append(cat_val)\n",
    "            break\n",
    "    if cat_val not in skiphuc:\n",
    "        yfhucdict[cat_val] = yfmoddict\n",
    "        ofhucdict[cat_val] = ofmoddict\n",
    "        \n",
    "young = pd.DataFrame(yfhucdict).T\n",
    "old = pd.DataFrame(ofhucdict).T\n",
    "young.dropna(axis='index', how='any', inplace=True)\n",
    "old.dropna(axis='index', how='any', inplace=True)\n",
    "    \n",
    "Prho_y1y, Pp_y1y = stats.pearsonr(np.array(young[x1]), np.array(young[y1]))\n",
    "Srho_y1y, Sp_y1y = stats.spearmanr(np.array(young[x1]), np.array(young[y1]))\n",
    "std_y1y = stats.tstd(np.array(young[x1]) - np.array(young[y1]))\n",
    "ME_y1y = np.mean(np.array(young[x1]) - np.array(young[y1]))\n",
    "Prho_y2y, Pp_y2y = stats.pearsonr(np.array(young[x2]), np.array(young[y2]))\n",
    "Srho_y2y, Sp_y2y = stats.spearmanr(np.array(young[x2]), np.array(young[y2]))\n",
    "std_y2y = stats.tstd(np.array(young[x2]) - np.array(young[y2]))\n",
    "ME_y2y = np.mean(np.array(young[x2]) - np.array(young[y2]))\n",
    "Prho_y1o, Pp_y1o = stats.pearsonr(np.array(old[x1]), np.array(old[y1]))\n",
    "Srho_y1o, Sp_y1o = stats.spearmanr(np.array(old[x1]), np.array(old[y1]))\n",
    "std_y1o = stats.tstd(np.array(old[x1]) - np.array(old[y1]))\n",
    "ME_y1o = np.mean(np.array(old[x1]) - np.array(old[y1]))\n",
    "Prho_y2o, Pp_y2o = stats.pearsonr(np.array(old[x1]), np.array(old[y2]))\n",
    "Srho_y2o, Sp_y2o = stats.spearmanr(np.array(old[x1]), np.array(old[y2]))\n",
    "std_y2o = stats.tstd(np.array(old[x2]) - np.array(old[y2]))\n",
    "ME_y2o = np.mean(np.array(old[x2]) - np.array(old[y2]))    \n",
    "\n",
    "#plotting\n",
    "miny, maxy = min(yfvalues), max(yfvalues)\n",
    "mino, maxo = min(ofvalues), max(ofvalues)\n",
    "yrange_y = maxy-miny\n",
    "yrange_o = maxo-mino\n",
    "\n",
    "young.plot(kind='scatter', x=x1, y=y1, marker='o', c='green', label='uniform n: hetero. K vs zoned K', ax=ax1)\n",
    "young.plot(kind='scatter', x=x2, y=y2, marker='^', c='blue', label='hetero. n: hetero. K vs zoned K', ax=ax1)\n",
    "old.plot(kind='scatter', x=x1, y=y1, marker='o', c='green', ax=ax2)\n",
    "old.plot(kind='scatter', x=x2, y=y2, marker='^', c='blue', ax=ax2)\n",
    "ax1.text(miny, miny+0.80*yrange_y, r'$r_p$ = {:3.3f}'.format(Prho_y1y), fontsize=9, color='green')\n",
    "ax1.text(miny, miny+0.75*yrange_y, r'$r_s$ = {:3.3f}'.format(Srho_y1y), fontsize=9, color='green')\n",
    "ax1.text(miny, miny+0.70*yrange_y, r'$std$ = {:3.3f}'.format(std_y1y), fontsize=9, color='green')\n",
    "ax1.text(miny, miny+0.65*yrange_y, r'$ME$ = {:3.3f}'.format(ME_y1y), fontsize=9, color='green')\n",
    "ax1.text(miny, miny+0.60*yrange_y, r'$r_p$ = {:3.3f}'.format(Prho_y2y), fontsize=9, color='blue')\n",
    "ax1.text(miny, miny+0.55*yrange_y, r'$r_s$ = {:3.3f}'.format(Srho_y2y), fontsize=9, color='blue')\n",
    "ax1.text(miny, miny+0.50*yrange_y, r'$std$ = {:3.3f}'.format(std_y2y), fontsize=9, color='blue')\n",
    "ax1.text(miny, miny+0.45*yrange_y, r'$ME$ = {:3.3f}'.format(ME_y2y), fontsize=9, color='blue')\n",
    "ax2.text(mino, mino+yrange_o, r'$r_p$ = {:3.3f}'.format(Prho_y1o), fontsize=9, color='green')\n",
    "ax2.text(mino, mino+0.95*yrange_o, r'$r_s$ = {:3.3f}'.format(Srho_y1o), fontsize=9, color='green')\n",
    "ax2.text(mino, mino+0.90*yrange_o, r'$std$ = {:3.3f}'.format(std_y1o), fontsize=9, color='green')\n",
    "ax2.text(mino, mino+0.85*yrange_o, r'$ME$ = {:3.3f}'.format(ME_y1o), fontsize=9, color='green')\n",
    "ax2.text(mino, mino+0.80*yrange_o, r'$r_p$ = {:3.3f}'.format(Prho_y2o), fontsize=9, color='blue')\n",
    "ax2.text(mino, mino+0.75*yrange_o, r'$r_s$ = {:3.3f}'.format(Srho_y2o), fontsize=9, color='blue')\n",
    "ax2.text(mino, mino+0.70*yrange_o, r'$std$ = {:3.3f}'.format(std_y2o), fontsize=9, color='blue')\n",
    "ax2.text(mino, mino+0.65*yrange_o, r'$ME$ = {:3.3f}'.format(ME_y2o), fontsize=9, color='blue')\n",
    "\n",
    "ax1.plot((miny, maxy), (miny, maxy), 'k--')\n",
    "ax2.plot((mino, maxo), (mino, maxo), 'k--')\n",
    "ax1.set_xlabel(''), ax1.set_ylabel(''), ax2.set_ylabel(''), ax2.set_xlabel('')\n",
    "fig.text(0.25, 0.82, 'Young Water')\n",
    "fig.text(0.73, 0.82, 'Old Water', ha='center')\n",
    "fig.text(0.07, 0.45, 'Median age (yrs) for the zoned K Modflow models', va='center', rotation='vertical')\n",
    "fig.text(0.5, 0.01, 'Median age (yrs) for the heterogeneous K Modflow models', ha='center')\n",
    "plt.subplots_adjust(top = .8)\n",
    "fig.suptitle('Comparison of median ages for young and\\n old water in the glacial aquifer by {}: heterogeneous vs zoned K.'.format(category), fontsize=14)\n",
    "#fig.tight_layout()\n",
    "\n",
    "dst = 'YnOages_121_hetn_hK2zK_{}'.format(category)\n",
    "dst_pth = os.path.join(fig_dir, dst)\n",
    "plt.savefig(dst_pth)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1:1 plot of median-YF-age and mOFage for complex (X) versus simple (Y) MF models for uniform and heterogeneous porosities \n",
    "# for ALL HUC scales\n",
    "\n",
    "# That is, does adding heterogeneous porosity also improve median ages as it did with YF calculations for simple and complex\n",
    "# MF models?\n",
    "\n",
    "x1, y1, x2, y2 = eptlist[0], eptlist[2], eptlist[1], eptlist[3]  # columns in eptlist. In this case (x=complexe MF; y=simple MF)\n",
    "\n",
    "hucs = ['HUC6', 'HUC8', 'HUC10', 'HUC12']\n",
    "nhucs = len(hucs)\n",
    "fig1, [[ax1, ax2], [ax3, ax4]] = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "fig2, [[ax5, ax6], [ax7, ax8]] = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "youngaxisdict = {0:ax1, 1:ax2, 2:ax3, 3:ax4}\n",
    "oldaxisdict = {0:ax5, 1:ax6, 2:ax7, 3:ax8}\n",
    "\n",
    "for k, each in enumerate(hucs):\n",
    "    # make sure we get ALL unique HUC IDs\n",
    "    u1 = dfdict[eptlist[0]][each].unique()\n",
    "    u2 = dfdict[eptlist[1]][each].unique()\n",
    "    u = np.append(u1, u2)\n",
    "    uniques = np.unique(u)\n",
    "    # remove any HUCs listed in purge_hucs\n",
    "    for h in purge_hucs:\n",
    "        ind = np.where(uniques==h)\n",
    "        uniques = np.delete(uniques, ind)\n",
    "    youngaxis = youngaxisdict[k]\n",
    "    oldaxis = oldaxisdict[k]\n",
    "    ofhucdict = {}\n",
    "    yfhucdict = {}\n",
    "    yfvalues = []\n",
    "    ofvalues = []\n",
    "    skiphuc = []\n",
    "    for j, cat_val in enumerate(uniques):  # each HUC ID\n",
    "        yfmoddict = {} \n",
    "        ofmoddict = {} \n",
    "        for i, md in enumerate(eptlist):  # each of the 3 FWP models\n",
    "            mn = eptlist[i]\n",
    "            df = dfdict[md].loc[dfdict[md][each]==cat_val]\n",
    "            if df.rt.count() >= minptl:\n",
    "                youngdf = df.loc[df.rt < age_cutoff]\n",
    "                olddf = df.loc[df.rt >= age_cutoff]\n",
    "                yfage = youngdf.rt.median()\n",
    "                ofage = olddf.rt.median()\n",
    "                yfmoddict[mn] = yfage\n",
    "                yfvalues.append(yfage) \n",
    "                ofmoddict[mn] = ofage\n",
    "                ofvalues.append(ofage)                \n",
    "            else:\n",
    "                skiphuc.append(cat_val)\n",
    "                break\n",
    "        if cat_val not in skiphuc:\n",
    "            yfhucdict[cat_val] = yfmoddict\n",
    "            ofhucdict[cat_val] = ofmoddict            \n",
    "            \n",
    "    young = pd.DataFrame(yfhucdict).T\n",
    "    old = pd.DataFrame(ofhucdict).T\n",
    "    young.dropna(axis='index', how='any', inplace=True)  # better way to remove NANs\n",
    "    old.dropna(axis='index', how='any', inplace=True)\n",
    "    Prho_y1y, Pp_y1y = stats.pearsonr(np.array(young[x1]), np.array(young[y1]))\n",
    "    Srho_y1y, Sp_y1y = stats.spearmanr(np.array(young[x1]), np.array(young[y1]))\n",
    "    std_y1y = stats.tstd(np.array(young[x1]) - np.array(young[y1]))\n",
    "    ME_y1y = np.mean(np.array(young[x1]) - np.array(young[y1]))\n",
    "    Prho_y2y, Pp_y2y = stats.pearsonr(np.array(young[x2]), np.array(young[y2]))\n",
    "    Srho_y2y, Sp_y2y = stats.spearmanr(np.array(young[x2]), np.array(young[y2]))\n",
    "    std_y2y = stats.tstd(np.array(young[x2]) - np.array(young[y2]))\n",
    "    ME_y2y = np.mean(np.array(young[x2]) - np.array(young[y2]))\n",
    "    Prho_y1o, Pp_y1o = stats.pearsonr(np.array(old[x1]), np.array(old[y1]))\n",
    "    Srho_y1o, Sp_y1o = stats.spearmanr(np.array(old[x1]), np.array(old[y1]))\n",
    "    std_y1o = stats.tstd(np.array(old[x1]) - np.array(old[y1]))\n",
    "    ME_y1o = np.mean(np.array(old[x1]) - np.array(old[y1]))\n",
    "    Prho_y2o, Pp_y2o = stats.pearsonr(np.array(old[x1]), np.array(old[y2]))\n",
    "    Srho_y2o, Sp_y2o = stats.spearmanr(np.array(old[x1]), np.array(old[y2]))\n",
    "    std_y2o = stats.tstd(np.array(old[x2]) - np.array(old[y2]))\n",
    "    ME_y2o = np.mean(np.array(old[x2]) - np.array(old[y2]))     \n",
    "    \n",
    "    #plotting\n",
    "    miny, maxy = min(yfvalues), max(yfvalues)\n",
    "    mino, maxo = min(ofvalues), max(ofvalues)\n",
    "    yrange_y = maxy-miny\n",
    "    yrange_o = maxo-mino\n",
    "    \n",
    "    if k == 0:\n",
    "        young.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', label='uniform n: hetero. K vs zoned K', ax=youngaxis)\n",
    "        young.plot(kind='scatter', x=x2, y=y2, marker='^', color='blue', label = 'hetero. n: hetero. K vs zoned K', ax=youngaxis)\n",
    "        \n",
    "        old.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', label='uniform n: hetero. K vs zoned K', ax=oldaxis)\n",
    "        old.plot(kind='scatter', x=x2, y=y2, marker='^', color='blue', label = 'hetero. n: hetero. K vs zoned K', ax=oldaxis)  \n",
    "        #youngaxis.text(miny, miny+0.83*yrange_y, 'R2 = {:3.3f}'.format(r2_y1y), fontsize=9, color='green')\n",
    "        youngaxis.text(miny, miny+0.83*yrange_y, r'$r_p$ = {:3.3f}'.format(Prho_y1y), fontsize=9, color='green')\n",
    "        youngaxis.text(miny, miny+0.78*yrange_y, r'$r_s$ = {:3.3f}'.format(Srho_y1y), fontsize=9, color='green')\n",
    "        youngaxis.text(miny, miny+0.73*yrange_y, r'$std$ = {:3.3f}'.format(std_y1y), fontsize=9, color='green')\n",
    "        youngaxis.text(miny, miny+0.68*yrange_y, r'$ME$ = {:3.3f}'.format(ME_y1y), fontsize=9, color='green')\n",
    "        #youngaxis.text(miny, miny+0.78*yrange_y, 'R2 = {:3.3f}'.format(r2_y2y), fontsize=9, color='blue')\n",
    "        youngaxis.text(miny, miny+0.63*yrange_y, r'$r_p$ = {:3.3f}'.format(Prho_y2y), fontsize=9, color='blue')\n",
    "        youngaxis.text(miny, miny+0.58*yrange_y, r'$r_s$ = {:3.3f}'.format(Srho_y2y), fontsize=9, color='blue')\n",
    "        youngaxis.text(miny, miny+0.53*yrange_y, r'$std$ = {:3.3f}'.format(std_y2y), fontsize=9, color='blue')\n",
    "        youngaxis.text(miny, miny+0.48*yrange_y, r'$ME$ = {:3.3f}'.format(ME_y2y), fontsize=9, color='blue')\n",
    "        #oldaxis.text(mino, mino+0.83*yrange_o, 'R2 = {:3.3f}'.format(r2_y1o), fontsize=9, color='green')\n",
    "        oldaxis.text(mino, mino+0.83*yrange_o, r'$r_p$ = {:3.3f}'.format(Prho_y1o), fontsize=9, color='green')\n",
    "        oldaxis.text(mino, mino+0.78*yrange_o, r'$r_s$ = {:3.3f}'.format(Srho_y1o), fontsize=9, color='green')\n",
    "        oldaxis.text(mino, mino+0.73*yrange_o, r'$std$ = {:3.3f}'.format(std_y1o), fontsize=9, color='green')\n",
    "        oldaxis.text(mino, mino+0.68*yrange_o, r'$ME$ = {:3.3f}'.format(ME_y1o), fontsize=9, color='green')\n",
    "        #oldaxis.text(mino, mino+0.78*yrange_o, 'R2 = {:3.3f}'.format(r2_y2o), fontsize=9, color='blue')\n",
    "        oldaxis.text(mino, mino+0.63*yrange_o, r'$r_p$ = {:3.3f}'.format(Prho_y2o), fontsize=9, color='blue')\n",
    "        oldaxis.text(mino, mino+0.58*yrange_o, r'$r_s$ = {:3.3f}'.format(Srho_y2o), fontsize=9, color='blue')\n",
    "        oldaxis.text(mino, mino+0.53*yrange_o, r'$std$ = {:3.3f}'.format(std_y2o), fontsize=9, color='blue')\n",
    "        oldaxis.text(mino, mino+0.48*yrange_o, r'$ME$ = {:3.3f}'.format(ME_y2o), fontsize=9, color='blue')\n",
    "    else:\n",
    "        young.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', ax=youngaxis)\n",
    "        young.plot(kind='scatter', x=x2, y=y2, marker='^', color='blue', ax=youngaxis)\n",
    "        old.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', ax=oldaxis)\n",
    "        old.plot(kind='scatter', x=x2, y=y2, marker='^', color='blue', ax=oldaxis)     \n",
    "        youngaxis.text(miny, miny+yrange_y, r'$r_p$ = {:3.3f}'.format(Prho_y1y), fontsize=9, color='green')\n",
    "        youngaxis.text(miny, miny+0.95*yrange_y, r'$r_s$ = {:3.3f}'.format(Srho_y1y), fontsize=9, color='green')\n",
    "        youngaxis.text(miny, miny+0.90*yrange_y, r'$std$ = {:3.3f}'.format(std_y1y), fontsize=9, color='green')\n",
    "        youngaxis.text(miny, miny+0.85*yrange_y, r'$ME$ = {:3.3f}'.format(ME_y1y), fontsize=9, color='green')\n",
    "        youngaxis.text(miny, miny+0.80*yrange_y, r'$r_p$ = {:3.3f}'.format(Prho_y2y), fontsize=9, color='blue')\n",
    "        youngaxis.text(miny, miny+0.75*yrange_y, r'$r_s$ = {:3.3f}'.format(Srho_y2y), fontsize=9, color='blue')\n",
    "        youngaxis.text(miny, miny+0.70*yrange_y, r'$std$ = {:3.3f}'.format(std_y2y), fontsize=9, color='blue')\n",
    "        youngaxis.text(miny, miny+0.65*yrange_y, r'$ME$ = {:3.3f}'.format(ME_y2y), fontsize=9, color='blue')\n",
    "        oldaxis.text(mino, mino+yrange_o, r'$r_p$ = {:3.3f}'.format(Prho_y1o), fontsize=9, color='green')\n",
    "        oldaxis.text(mino, mino+0.95*yrange_o, r'$r_s$ = {:3.3f}'.format(Srho_y1o), fontsize=9, color='green')\n",
    "        oldaxis.text(mino, mino+0.90*yrange_o, r'$std$ = {:3.3f}'.format(std_y1o), fontsize=9, color='green')\n",
    "        oldaxis.text(mino, mino+0.85*yrange_o, r'$ME$ = {:3.3f}'.format(ME_y1o), fontsize=9, color='green')\n",
    "        oldaxis.text(mino, mino+0.80*yrange_o, r'$r_p$ = {:3.3f}'.format(Prho_y2o), fontsize=9, color='blue')\n",
    "        oldaxis.text(mino, mino+0.75*yrange_o, r'$r_s$ = {:3.3f}'.format(Srho_y2o), fontsize=9, color='blue')\n",
    "        oldaxis.text(mino, mino+0.70*yrange_o, r'$std$ = {:3.3f}'.format(std_y2o), fontsize=9, color='blue')\n",
    "        oldaxis.text(mino, mino+0.65*yrange_o, r'$ME$ = {:3.3f}'.format(ME_y2o), fontsize=9, color='blue')\n",
    "        \n",
    "    youngaxis.plot((miny, maxy), (miny, maxy), 'k--')\n",
    "    oldaxis.plot((mino, maxo), (mino, maxo), 'k--')\n",
    "\n",
    "    youngaxis.set_xlabel(''), youngaxis.set_ylabel(''), oldaxis.set_xlabel(''), oldaxis.set_ylabel('')\n",
    "    youngaxis.set_title(each)\n",
    "    oldaxis.set_title(each)\n",
    "    \n",
    "    # Add an attribute to the HUC shapefile\n",
    "    #shapefile = HUCshpdict[each]\n",
    "    #shp = gpd.read_file(shapefile)  \n",
    "    #shp[each] = shp[each].astype('int64')  # convert so can merge\n",
    "    \n",
    "    #young.index = young.index.astype('int64')  # convert so can merge\n",
    "    #young['mYage_{}-{}'.format(scenario_name, base_case)] = young[x1] - young[y1]\n",
    "    ##young['mYage_hK-zK'] = young[x1] - young[y2]\n",
    "    #df = pd.merge(shp, young, how='outer', left_on=each, right_index=True)\n",
    "    #dst = shapefile[:-4] + '_mYage_{}.shp'.format(scenario_name)\n",
    "    #df.to_file(dst)\n",
    "    \n",
    "    #old.index = old.index.astype('int64')  # convert so can merge\n",
    "    #old['mOage_{}-{}'.format(scenario_name, base_case)] = old[x1] - old[y1]\n",
    "    ##old['mOage_hK-zK'] = old[x1] - old[y2]\n",
    "    #dfo = pd.merge(shp, old, how='outer', left_on=each, right_index=True)\n",
    "    #dsto = shapefile[:-4] + '_mOage_{}.shp'.format(scenario_name)\n",
    "    #dfo.to_file(dsto)\n",
    "\n",
    "#fig1.text(0.46, 0.92, 'Young fraction', fontsize=12)\n",
    "#fig.text(0.71, 0.92, 'Old fraction', ha='center', fontsize=12)\n",
    "#fig2.text(0.48, 0.92, 'Old fraction', fontsize=12)\n",
    "fig1.text(0.5, 0.055, 'Median age (yrs) for the 5-layer heterogeneous K Modflow models', ha='center', fontsize=12)\n",
    "fig1.text(0.001, 0.48, 'Median age (yrs) for the 5-layer zoned K Modflow models', va='center', fontsize=12, rotation='vertical')\n",
    "fig2.text(0.5, 0.055, 'Median age (yrs) for the 5-layer heterogeneous K Modflow models', ha='center', fontsize=12)\n",
    "fig2.text(0.005, 0.48, 'Median age (yrs) for the 5-layer zoned K Modflow models', va='center', fontsize=12, rotation='vertical')\n",
    "plt.subplots_adjust(top = .89)\n",
    "fig1.suptitle('Comparison of median ages for young fraction in the\\n glacial aquifer by HUCs: heterogeneous vs zoned K.', fontsize=16)\n",
    "fig2.suptitle('Comparison of median ages for old fraction in the\\n glacial aquifer by HUCs: heterogeneous vs zoned K.', fontsize=16)\n",
    "\n",
    "dst1 = 'Yages_121_hetn_hK2zK_allHUCs'\n",
    "dst2 = 'Oages_121_hetn_hK2zK_allHUCs'\n",
    "dst_pth1 = os.path.join(fig_dir, dst1)\n",
    "dst_pth2 = os.path.join(fig_dir, dst2)\n",
    "fig1.savefig(dst_pth1)\n",
    "fig2.savefig(dst_pth2)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "\n",
    "#  https://stackoverflow.com/questions/20144529/shifted-colorbar-matplotlib/20146989#20146989\n",
    "class MidpointNormalize(Normalize):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        # I'm ignoring masked values and all kinds of edge cases to make a\n",
    "        # simple example...\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate DF with zonal stats\n",
    "def hucpropstats2(hucrast, proprast, dataframe, raster_file, metric, descriptor):  # fluxtype, mod_factor\n",
    "    #descriptor = '{}_{}_{}'.format(metric, fluxtype, mod_factor)\n",
    "    df = dataframe.copy()\n",
    "    #df[metric] = 0  # initialize\n",
    "    df[descriptor] = 0  # initialize\n",
    "    u = np.unique(hucrast)\n",
    "    if max(u) < 10000:  # Less than any HUC6 ID number\n",
    "        with open(raster_file.split('.')[0] + '_crossref.txt', mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            next(reader, None)  # skip the headers\n",
    "            crossdict = {int(rows[0]):np.int64(rows[1]) for rows in reader}\n",
    "\n",
    "    for ID in u[u>0]:  # HUC IDs in active part of model (not ID zero)\n",
    "        idarr = np.zeros_like(hucrast)\n",
    "        idarr[hucrast==ID] = 1\n",
    "        hucprop = idarr * proprast\n",
    "        hucprop[hucprop==0] = np.nan\n",
    "        pmn, pmed, psum, pmin, pmax, pstd, pcount = np.nanmean(hucprop), np.nanmedian(hucprop), np.nansum(hucprop), np.nanmin(hucprop), np.nanmax(hucprop), np.nanstd(hucprop), np.count_nonzero(~np.isnan(hucprop))\n",
    "        prange = pmax - pmin\n",
    "        metricdict = {'mean':pmn, 'median':pmed, 'sum':psum, 'min':pmin, 'max':pmax, 'range':prange, 'std':pstd, 'count':pcount}\n",
    "        if max(u) < 10000:\n",
    "            # assigned the appropriate zonal data\n",
    "            #df[metric].loc[df.index==crossdict[ID]] = metricdict[metric].astype('float64')              \n",
    "            try:\n",
    "                df[descriptor].loc[df.index==crossdict[ID]] = metricdict[metric].astype('float64')              \n",
    "            except:\n",
    "                df[descriptor].loc[df.index==crossdict[ID]] = int(metricdict[metric])\n",
    "        else:\n",
    "            # assigned the appropriate zonal data\n",
    "            #df[metric].loc[df.index==ID] = metricdict[metric].astype('float64')  \n",
    "            try:\n",
    "                df[descriptor].loc[df.index==ID] = metricdict[metric].astype('float64')  \n",
    "            except:\n",
    "                df[descriptor].loc[df.index==ID] = int(metricdict[metric])\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Evaluate model factors (weak sinks) when using heterogeneous n.  Does the pattern seen with uniform n still hold?\n",
    "\n",
    "# reduce the analysis to just the heterogeneous n results\n",
    "hetn_list = []\n",
    "hetn_list.append(eptlist[1])\n",
    "hetn_list.append(eptlist[3])\n",
    "x1, y1 = hetn_list[0], hetn_list[1]  # columns in eptlist. In this case (x=complexe MF; y=simple MF)\n",
    "\n",
    "# 1:1 plot of YoungFraction btwn 5LhK and 5LzK models for all HUC scales; color coded by differences in model output\n",
    "# among the 5LhK and 5LzK models.  What's causing the YF differences?\n",
    "\n",
    "topic = 'discharge'  # Chose between 'discharge' or 'seepage'.  Refers to dicts of tiffs for discharge to SFR cells or SFR cells seeping into aquifers\n",
    "metric = 'count'  # valid:  'mean', 'median', sum', min', 'max', 'range', 'std', 'count'\n",
    "\n",
    "hucs = ['HUC6', 'HUC8', 'HUC10', 'HUC12']\n",
    "nhucs = len(hucs)\n",
    "\n",
    "# loop this thing\n",
    "#for prop in HUCfluxrastlist:\n",
    "\n",
    "#for Qkey, prop in dischargerastdict.items():\n",
    "fig, [[ax1, ax2], [ax3, ax4]] = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "axisdict = {0:ax1, 1:ax2, 2:ax3, 3:ax4}\n",
    "\n",
    "for k, each in enumerate(hucs):\n",
    "    # make sure we get ALL unique HUC IDs\n",
    "    u1 = dfdict[eptlist[0]][each].unique()\n",
    "    u2 = dfdict[eptlist[1]][each].unique()\n",
    "    u3 = dfdict[eptlist[2]][each].unique()\n",
    "    u = np.append(u1, u2)\n",
    "    u = np.append(u, u3)\n",
    "    uniques = np.unique(u)\n",
    "    # remove any HUCs listed in purge_hucs\n",
    "    for h in purge_hucs:\n",
    "        ind = np.where(uniques==h)\n",
    "        uniques = np.delete(uniques, ind)\n",
    "    axis = axisdict[k]\n",
    "\n",
    "    yfhucdict = {}\n",
    "    yfvalues = []\n",
    "    skiphuc = []\n",
    "    for j, cat_val in enumerate(uniques.astype('int64')):  # each HUC ID\n",
    "        yfmoddict = {}            \n",
    "        #for i, md in enumerate(eptlist):  # each of the 3 FWP models\n",
    "        for i, md in enumerate(hetn_list):  # each of the 3 FWP models\n",
    "            mn = hetn_list[i]\n",
    "            df = dfdict[md].loc[dfdict[md][each]==cat_val]\n",
    "            if df.rt.count() >= minptl:\n",
    "                youngdf = df.loc[df.rt < age_cutoff]\n",
    "                yf = youngdf.rt.count() / df.rt.count()\n",
    "                yfmoddict[mn] = yf\n",
    "                yfvalues.append(yf)\n",
    "            else:\n",
    "                skiphuc.append(cat_val)\n",
    "                break\n",
    "        if cat_val not in skiphuc:\n",
    "            yfhucdict[cat_val] = yfmoddict    \n",
    "    ddd = pd.DataFrame(yfhucdict).T\n",
    "    for n in hetn_list:\n",
    "        ddd = ddd.loc[~ddd[n].isnull()]  # need to remove any NANs\n",
    "        \n",
    "    # run zonal_stats on the merged df. Use the 'HUC' Tiffs to match up with model properties\n",
    "    print('Processing HUCs for {}'.format(each))\n",
    "    raster_file = HUCtiffdict[each]\n",
    "    with rasterio.open(raster_file) as raster:\n",
    "        hucrast = raster.read()[0]\n",
    "        \n",
    "    #Process the \"evaluate flux rasters\"\n",
    "    for i in range(len(evaluate)):\n",
    "        modnm = evaluate[i]\n",
    "        if topic == 'discharge':\n",
    "            prop = dischargerastdict[modnm]\n",
    "        elif topic == 'seepage':\n",
    "            prop = lossrastdict[modnm]\n",
    "        else:\n",
    "            print('only \"discharge\" or \"seepage\" are valid entries for the \"topic\" variable.  Stopping.')\n",
    "            sys.exit()\n",
    "        fluxtype = os.path.basename(prop).split('.')[0].split('_')[-1]  # type of info in the rasters\n",
    "        print('Extracting zonal summary values from {} for {}'.format(prop, each))\n",
    "        with rasterio.open(prop) as raster:\n",
    "            fluxrast = raster.read()[0]\n",
    "            if np.nanmax(fluxrast) <= 0.0:  # convert all negative arrays to positive\n",
    "                fluxrast = fluxrast * -1\n",
    "        if i == 0:\n",
    "            mod_factor1 = abrevdict[modnm]\n",
    "            descript1 = '{}_{}_{}'.format(metric, fluxtype, mod_factor1)\n",
    "            firstflux = fluxrast.copy() \n",
    "            ddd1 = hucpropstats2(hucrast, firstflux, ddd, raster_file, metric, descript1) \n",
    "        elif i==1:\n",
    "            mod_factor2 = abrevdict[modnm]\n",
    "            descript2 = '{}_{}_{}'.format(metric, fluxtype, mod_factor2)\n",
    "            # process second raster.\n",
    "            ddd2 = hucpropstats2(hucrast, fluxrast, ddd1, raster_file, metric, descript2)\n",
    "            fluxdiff = firstflux - fluxrast\n",
    "            mod_factor3 = mod_factor1 + '-' + mod_factor2\n",
    "            descript3 = '{}_{}_{}'.format(metric, fluxtype, mod_factor3)\n",
    "            ddd2[descript3] = ddd2[descript1] - ddd2[descript2]\n",
    "            descript4 = '%change_{}'.format(descript3)\n",
    "            ddd2[descript4] = (ddd2[descript3] / ddd2[descript1]) * 100.0\n",
    "            ddd2.replace([np.inf, -np.inf], np.nan)  # just in case infinity is calculated. Convert to nan before purge nan.\n",
    "            ddd2 = ddd2.loc[ddd2[descript4].notnull()]  # remove any NANs\n",
    "        else:\n",
    "            print('Only 2 models were supposed to be listed in the EVALUATE variable.  Please fix that and re-run. Stopping.')\n",
    "            sys.exit()\n",
    "    \n",
    "    print('Preparing plots for {}'.format(each))\n",
    "    ddd2[mod_factor3] = ddd2[x1] - ddd2[y1]  # AGE difference\n",
    "    Srho_color, Sp_color = stats.spearmanr(np.array(ddd2[descript4]), np.array(ddd2[mod_factor3]))\n",
    "    Prho_color, Pp_color = stats.pearsonr(np.array(ddd2[descript4]), np.array(ddd2[mod_factor3]))\n",
    "    std_color = stats.tstd(np.array(ddd2[descript4]) - np.array(ddd2[mod_factor3]))\n",
    "    ME_color = np.mean(np.array(ddd2[descript4]) - np.array(ddd2[mod_factor3]))\n",
    "         \n",
    "    #plotting\n",
    "    mini = min(min(ddd2[x1]), min(ddd2[y1]))\n",
    "    maxi = max(max(ddd2[x1]), max(ddd2[y1]))\n",
    "    yrange = maxi-mini\n",
    "    norm = MidpointNormalize(midpoint=0)\n",
    "    ddd2.plot(kind='scatter', x=x1, y=y1, marker='^', c=ddd2[descript4], cmap='RdYlBu', norm=norm, ax=axis, vmax=ddd2[descript4].quantile(.99), vmin=ddd2[descript4].quantile(.01))\n",
    "    lowlim = min(axis.get_xlim()[0], axis.get_ylim()[0])\n",
    "    uplim = max(axis.get_xlim()[1], axis.get_ylim()[1])\n",
    "    lims = (lowlim, uplim)\n",
    "    lrange = uplim - lowlim\n",
    "    axis.set_xlim(lims)  # force the plots to be square\n",
    "    axis.set_ylim(lims)\n",
    "    axis.text(lowlim+0.03*lrange, uplim-0.11*lrange, 'Fit metrics between model property \\nand YF differences:', fontsize=9)\n",
    "    axis.text(lowlim+0.03*lrange, uplim-0.16*lrange, r'$r_p$ = {:3.3f}  $p$={:1.1e}'.format(Prho_color, Pp_color), fontsize=9)\n",
    "    axis.text(lowlim+0.03*lrange, uplim-0.21*lrange, r'$r_s$ = {:3.3f}  $p$={:1.1e}'.format(Srho_color, Sp_color), fontsize=9)\n",
    "    axis.text(lowlim+0.03*lrange, uplim-0.26*lrange, r'$std$ = {:3.3f}'.format(std_color), fontsize=9)\n",
    "    axis.text(lowlim+0.03*lrange, uplim-0.31*lrange, r'$ME$ = {:3.3f}'.format(ME_color), fontsize=9)\n",
    "    pos1 = axis.get_position()\n",
    "    axis.plot((mini, maxi), (mini, maxi), 'k--')\n",
    "    axis.annotate(\"\", xy=(mini+0.32*yrange, maxi-0.35*yrange), xytext=(mini+0.48*yrange, mini+0.52*yrange), arrowprops=dict(arrowstyle=\"->\", lw=3, color='gray', alpha=0.3))  # orange\n",
    "    axis.annotate(\"\", xy=(maxi-0.32*yrange, mini+0.35*yrange), xytext=(mini+0.52*yrange, mini+0.48*yrange), arrowprops=dict(arrowstyle=\"->\", lw=3, color='gray', alpha=0.3))  # royalblue\n",
    "    axis.set_xlabel(''), axis.set_ylabel('')\n",
    "    axis.set_title(descript3)\n",
    "\n",
    "fig.text(0.5, 0.105, 'Young Fraction for the 5-layer variable K model', ha='center', fontsize=12)\n",
    "fig.text(0.07, 0.48, 'Young Fraction for the 5-layer zoned K model', va='center', fontsize=12, rotation='vertical')\n",
    "plt.subplots_adjust(top = .86, bottom = 0.15)\n",
    "fig.suptitle('Comparison of Young Fraction by HUC scale, as informed by model \\n'\n",
    "         'property:  %change in {} of {}'.format(metric, fluxtype), fontsize=16)\n",
    "dst = '5LhetN_YFCompare_by_%del_{}_of_{}_of_{}.png'.format(metric, fluxtype, mod_factor3)\n",
    "dst_pth = os.path.join(fig_dir, dst)\n",
    "f = plt.gcf()\n",
    "f.savefig(dst_pth)\n",
    "\n",
    "# Add an attribute to the HUC shapefile\n",
    "#shapefile = HUCshpdict[each]\n",
    "#path = os.path.dirname(HUCshpdict[each])\n",
    "#shp = gpd.read_file(shapefile)  \n",
    "#shp[each] = shp[each].astype('int64')  # convert so can merge\n",
    "\n",
    "#ddd2.index = ddd2.index.astype('int64')  # convert so can merge\n",
    "#df = pd.merge(shp, ddd2, how='outer', left_on=each, right_index=True)\n",
    "#dst = os.path.join(path, '{}_YF_{}_{}.shp'.format(each, fluxtype, metric))\n",
    "#df.to_file(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
