{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script loads EPT files, calculates YF and median age YF, then makes 1:1 plots to compare simplified models to the most complex model.  The goal is to evaluate if and how complexity influences age metrics across scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The script reads in the model_grid.csv file for each model and uses that to tie each particle's initial location to select categories, such as the HUC, NLCD, coarse fraction, etc.\n",
    "\n",
    "#### This code has been updated to only work with the FLUX-weighted age simulations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'Paul Juckem'\n",
    "%matplotlib notebook\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "from datetime import datetime\n",
    "import gdal\n",
    "from gdal import ogr, osr\n",
    "import gen_mod_functions as gm\n",
    "import flopy as fp\n",
    "import pickle\n",
    "from ipywidgets import interact, Dropdown, Text\n",
    "from IPython.display import display\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import csv\n",
    "\n",
    "try:\n",
    "    import rasterio\n",
    "except:\n",
    "    print('Install rasterio into your python environment. Or, skip plotting of geotiffs at the end of this notebook')\n",
    "\n",
    "# Try not to use these!!\n",
    "#from gen_mod_dict import *\n",
    "#from model_specs import *\n",
    "\n",
    "modifier = False\n",
    "def ReturnEntry(sender):\n",
    "    modifier.value = intext.value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify user input, including list of models to compare and which axes to plot them, plus attributes to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_aq_lays = 3  # deepest layer of the surficial aquifer.\n",
    "\n",
    "simulate_list = ['FWP1L_zK', 'FWP5L_zK', 'FWP5L_hK'] \n",
    "nrow, ncol = 930, 650  # just easier to hardcode this.\n",
    "\n",
    "# for plotting 1:1 graphs\n",
    "x1, y1, y2 = 'FWP5L_hK', 'FWP1L_zK', 'FWP5L_zK'\n",
    "\n",
    "# Columns in the model_grid.csv file to keep.  Purge all others.\n",
    "mg_columns = ['node_num', 'row', 'col', 'HUC6', 'HUC8', 'HUC10', 'HUC12', 'ibound', 'gage_id', 'coarse_flag', \n",
    "              'qu_atlas', 'catchment', 'ssurgo', 'stream_order', 'surfmat']\n",
    "\n",
    "category = 'HUC8' \n",
    "genHUCdict = {'Oconto':'04030104', 'TWR':'0403020218'}\n",
    "\n",
    "minptl = 50  # The minimum number of particles for EACH model within each HUC (eg: if FWP5L has 2000, \n",
    "               # but FWP1L has 800, none get plotted in the 1:1 plots.  Still included in the RTD plots.)\n",
    "               # 1000 seems to be a good number for 1:1 plots as it includes only HUCs with really refined RTDs;\n",
    "               # however, 50 or 100 seems more reasonable if we want to visualize spatial patterns because it\n",
    "               # allows more HUCs to be plotted.  50-100 is based on visually inspecting RTD curves.\n",
    "                \n",
    "purge_hucs = [40602, 4060200, 406020000, 40602000000]  # all hucs for Lake Michigan      \n",
    "\n",
    "HUCtiffdict = {'HUC6':'E:/HUCS/WBD_4n7/HUC6_UTMft_FWP.tiff', \n",
    "              'HUC8':'E:/HUCS/WBD_4n7/HUC8_UTMft_FWP.tiff', \n",
    "              'HUC10':'E:/HUCS/WBD_4n7/HUC10_UTMft_FWP.tiff',\n",
    "              'HUC12':'E:/HUCS/WBD_4n7/HUC12_UTMft_FWP.tiff'}\n",
    "\n",
    "#HUCproprast = './vK_lay1_hK-vK.tif'\n",
    "HUCproprastlist = ['./vK_lay1_5h-5z.tif', './vK_lay2_5h-5z.tif', './vK_lay3_5h-5z.tif', './vK_lay1_hK-vK.tif',\n",
    "                 './vani_lay1_5h-5z.tif', './vani_lay2_5h-5z.tif', './vani_lay3_5h-5z.tif',\n",
    "                 './T_lay1_5h-5z.tif', './T_lay2_5h-5z.tif', './T_lay3_5h-5z.tif', './GlacT_5h-5z.tif',\n",
    "                 './glac_satthick_5h-5z.tif', './BrRCH_5h-5z.tif', './RCH_5h-5z.tif', \n",
    "                 './hK_lay1_5h-5z.tif', './hK_lay2_5h-5z.tif', './hK_lay3_5h-5z.tif',\n",
    "                 './BrT_5h-5z.tif', './glacT2BrT_5h-5z.tif', './RCHUZF_5h-5z.tif', './UZF_5h-5z.tif', \n",
    "                 './RCHcbb_5h-5z.tif', './rch-over-satKs_5h-5z.tif', './sat-weighted_Ks_5h-5z.tif']\n",
    "HUCfluxrastlist = ['./SWleak_5h-5z.tif', './MNW2_5h-5z.tif', './SFR_5h-5z.tif']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep the script for the models to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homes = ['../Models']\n",
    "fig_dir = '../Figures'\n",
    "\n",
    "if not os.path.exists(fig_dir):\n",
    "    os.mkdir(fig_dir)  # PFJ:  dst is not defined; changed to fig_dir.\n",
    "\n",
    "mfpth = '../executables/MODFLOW-NWT_1.0.9/bin/MODFLOW-NWT_64.exe'\n",
    "mp_exe_name = '../executables/modpath.6_0/bin/mp6x64.exe' \n",
    "\n",
    "#mf_start_date_str = '01/01/1900' \n",
    "#mp_release_date_str = '01/01/2017' \n",
    "\n",
    "age_cutoff = 65\n",
    "#year_cutoff = '01/01/1952'\n",
    "\n",
    "surf_aq_lays = 3  # deepest layer of the surficial aquifer.\n",
    "\n",
    "dir_list = []\n",
    "modlist = []\n",
    "i = 0\n",
    "r = 0\n",
    "\n",
    "#model = {}\n",
    "path_dict = {}\n",
    "#modify = []\n",
    "#mod_type = {}\n",
    "dfdict = {}\n",
    "totp = {}\n",
    "for home in homes:\n",
    "    if os.path.exists(home):\n",
    "        for dirpath, dirnames, filenames in os.walk(home):\n",
    "            for f in filenames:\n",
    "                if os.path.splitext(f)[-1] == '.nam':\n",
    "                    mod = os.path.splitext(f)[0]\n",
    "                    i += 1\n",
    "                    if mod in simulate_list:\n",
    "                        modlist.append(mod)\n",
    "                        dir_list.append(dirpath)\n",
    "                        r += 1\n",
    "                        path_dict[mod] = dirpath\n",
    "                               \n",
    "print('    {} models read'.format(i))\n",
    "print('These {} models will be analyzed: {}'.format(r, modlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read-in the model_grid.csv file for each model.  Then create a dataframe from each csv & pickle file.\n",
    "\n",
    "dfdict = {}\n",
    "totp = {}\n",
    "\n",
    "for model in modlist:\n",
    "    g = os.path.join(path_dict[model], 'model_grid.csv')\n",
    "    try:\n",
    "        df = pd.read_csv(g)\n",
    "        df.ibound.replace(0, np.nan, inplace=True)\n",
    "        df = df[df.ibound.notnull()]\n",
    "        df = df[mg_columns]  # keep just the desired fields\n",
    "        # re-calculate 2D cell number\n",
    "        df['cellnum2d'] = df.row * ncol + df.col\n",
    "        #df.rename(columns={'node_num':'initial_node_num'}, inplace=True)\n",
    "\n",
    "        p = os.path.join(path_dict[model], '{}_flux_all_zones_mod.pickle'.format(model))\n",
    "        eptu = pd.read_pickle(open(p, 'rb'))\n",
    "        eptu['cellnum2d'] = (eptu['Initial Row']-1) * ncol + (eptu['Initial Column'] -1)  # -1 to convert to 0-based\n",
    "        eptu_mg = eptu.join(df, on='cellnum2d', lsuffix='_ept', rsuffix='_mg')\n",
    "        eptu_mg = eptu_mg[eptu_mg['Initial Layer'] <= surf_aq_lays]  # ensure that we're only analyzing Glacial!\n",
    "        dfdict[model] = eptu_mg\n",
    "        totp[model] = eptu_mg.rt.count()\n",
    "\n",
    "    except (AttributeError, ValueError, IOError, IndexError):\n",
    "        print('ERROR. THIS CODE BLOCK DID NOT COMPLETE. TROUBLE-SHOOT AND TRY AGAIN')\n",
    "        print('The error occured while working on this model: {}'.format(model))\n",
    "        raise SystemExit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot age distributions for all 3 models by HUC ID, for selected HUC scale.\n",
    "\n",
    "uniques = dfdict[modlist[0]][category].unique()\n",
    "# remove any HUCs listed in purge_hucs\n",
    "for h in purge_hucs:\n",
    "    ind = np.where(uniques==h)\n",
    "    uniques = np.delete(uniques, ind)\n",
    "\n",
    "n_uni = len(uniques)\n",
    "sum_p = {}\n",
    "for mn in modlist:\n",
    "    sum_p[mn] = 0\n",
    "    \n",
    "#if portrait:\n",
    "#    vplots = int(np.ceil(len(uniques)/ 3.0))\n",
    "#    figsize = (10, 3*vplots)\n",
    "#    CS, CSaxes = plt.subplots(vplots, 3, figsize=figsize)\n",
    "\n",
    "#else:\n",
    "if n_uni <= 20:\n",
    "    vplots = int(np.ceil(n_uni/ 3.0))\n",
    "    figsize = (12, 3*vplots)\n",
    "    CS, CSaxes = plt.subplots(vplots, 3, figsize=figsize)\n",
    "else:\n",
    "    hplots = int(np.round(np.sqrt(n_uni)))\n",
    "    vplots = int(np.ceil(np.sqrt(n_uni)))\n",
    "    figsize = (hplots*4, hplots*3)\n",
    "    CS, CSaxes = plt.subplots(vplots, hplots, figsize=figsize)\n",
    "        \n",
    "colors_line = plt.cm.brg(np.linspace(0, 1, len(modlist)))\n",
    "\n",
    "for ax, cat_val in zip(CSaxes.flat, uniques):\n",
    "    n = []\n",
    "    for i, md in enumerate(modlist):\n",
    "\n",
    "        rt = dfdict[md].loc[dfdict[md][category]==cat_val, 'rt']  # 'rt' is \"raw time\" in the dataframe\n",
    "        rt.sort_values(inplace=True)\n",
    "        n.append(rt.count())\n",
    "        sum_p[md] = sum_p[md] + rt.count()\n",
    "        y_rt = np.linspace(0, 1, rt.shape[0])\n",
    "\n",
    "        ax.plot(rt, y_rt, c=colors_line[i], label=md)\n",
    "        ax.plot((65, 65), (0.2, 1), 'k--')\n",
    "        \n",
    "        title = '{}: {}'.format(category, cat_val)\n",
    "        ax.set_title(title, fontsize=12)\n",
    "\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlim(1e0, 1e3)\n",
    "        ax.set_ylim(0, )\n",
    "\n",
    "        ax.legend(loc=0, frameon=False, fontsize=8)#, bbox_to_anchor=(0.20, 0.2), ncol=1)\n",
    "        ax.set_xlabel('Residence time, in years')\n",
    "        ax.set_ylabel('Cumulative frequency')\n",
    "        if len(n) == len(modlist):\n",
    "            nmin, nmax = min(n), max(n)\n",
    "            ax.text(5,0.02, '# particles: {:,} - {:,}'.format(nmin, nmax))\n",
    "        \n",
    "CS.suptitle('Comparison of glacial particle time distributions by {} for the FWP models'.format(category), fontsize=18)  \n",
    "CS.tight_layout()\n",
    "#if portrait:\n",
    "#    CS.subplots_adjust(top= 1-(n_uni/3*0.021), hspace=0.5)  # so suptitle doesn't get over-lapped when using tight_layout\n",
    "#else:#  6: 0.86 is ideal.  18: 0.89-0.9 is ideal, 102: 0.95-0.96,  443: 0.97\n",
    "if n_uni < 18:\n",
    "    #CS.subplots_adjust(top= 0.86, hspace=0.85)\n",
    "    CS.subplots_adjust(top= 0.86)\n",
    "elif n_uni < 100:\n",
    "    CS.subplots_adjust(top= 0.89, hspace=0.55)\n",
    "elif n_uni < 400:\n",
    "    CS.subplots_adjust(top= 0.95, hspace=0.55)\n",
    "else:\n",
    "    CS.subplots_adjust(top= 0.97, hspace=0.55)\n",
    "\n",
    "#dst = 'RTD_compare--{}'.format(category)\n",
    "#loc = os.path.dirname(path[modlist[0]])  # should go up one directory to the dir that houses all of the models.\n",
    "#dst_pth = os.path.join(loc, dst)\n",
    "#plt.savefig(dst_pth)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 plot of Young Fraction btwn 5LhK against 1L and 5LzK models for select HUC scale.\n",
    "\n",
    "uniques = dfdict[modlist[0]][category].unique()\n",
    "# remove any HUCs listed in purge_hucs\n",
    "for h in purge_hucs:\n",
    "    ind = np.where(uniques==h)\n",
    "    uniques = np.delete(uniques, ind)\n",
    "\n",
    "yfhucdict = {}\n",
    "yfvalues = []\n",
    "skiphuc = []\n",
    "for j, cat_val in enumerate(uniques):  # each HUC ID\n",
    "    yfmoddict = {}\n",
    "    for i, md in enumerate(modlist):  # each of the 3 FWP models\n",
    "        #df = dfdict[md].loc[dfdict[md][category]==cat_val]\n",
    "        df = dfdict[md][dfdict[md][category]==cat_val].copy()\n",
    "        if df.rt.count() >= minptl:\n",
    "            youngdf = df.loc[df.rt < 65]\n",
    "            yf = youngdf.rt.count() / df.rt.count()\n",
    "            yfmoddict[md] = yf\n",
    "            yfvalues.append(yf)\n",
    "        else:\n",
    "            skiphuc.append(cat_val)\n",
    "            break\n",
    "    if cat_val not in skiphuc:\n",
    "        yfhucdict[cat_val] = yfmoddict    \n",
    "        \n",
    "ddd = pd.DataFrame(yfhucdict).T\n",
    "print(mean_squared_error(np.array(ddd[x1]), np.array(ddd[y1])))\n",
    "r2_y1 = r2_score(np.array(ddd[x1]), np.array(ddd[y1]))\n",
    "r2_y2 = r2_score(np.array(ddd[x1]), np.array(ddd[y2]))\n",
    "print(r2_y1)\n",
    "print(r2_y2)\n",
    "\n",
    "ax = ddd.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', label='1-layer zoned K')\n",
    "ddd.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', label = '5-layer zoned K', ax=ax)\n",
    "mini, maxi = min(yfvalues), max(yfvalues)\n",
    "y1x = maxi - ((maxi-mini)/2)\n",
    "ax.plot((mini, maxi), (mini, maxi), 'k--')\n",
    "plt.xlabel('Fraction of young water (<65 yr) in the complex model')\n",
    "plt.ylabel('Fraction of young water (<65 yr) in the simple models')\n",
    "plt.suptitle('Comparison of glacial young fraction\\n among models by {}'.format(category), fontsize=14)\n",
    "ax.text(0.76, maxi, 'R2 = {:3.3f}'.format(r2_y1), fontsize=9, color='green')\n",
    "ax.text(0.76, maxi-0.02, 'R2 = {:3.3f}'.format(r2_y2), fontsize=9, color='blue')\n",
    "\n",
    "#dst = 'YFrac_glac_121_{}'.format(category)\n",
    "#loc = os.path.dirname(path[modlist[0]])  # should go up one directory to the dir that houses all of the models.\n",
    "#dst_pth = os.path.join(loc, dst)\n",
    "#plt.savefig(dst_pth)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 plot of Young Fraction btwn 5LhK against 1L and 5LzK models for ALL HUC scales.\n",
    "\n",
    "hucs = ['HUC6', 'HUC8', 'HUC10', 'HUC12']\n",
    "nhucs = len(hucs)\n",
    "fig, [[ax1, ax2], [ax3, ax4]] = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "axisdict = {0:ax1, 1:ax2, 2:ax3, 3:ax4}\n",
    "\n",
    "for k, each in enumerate(hucs):\n",
    "    # make sure we get ALL unique HUC IDs\n",
    "    u1 = dfdict[modlist[0]][each].unique()\n",
    "    u2 = dfdict[modlist[1]][each].unique()\n",
    "    u3 = dfdict[modlist[2]][each].unique()\n",
    "    u = np.append(u1, u2)\n",
    "    u = np.append(u, u3)\n",
    "    uniques = np.unique(u)\n",
    "    # remove any HUCs listed in purge_hucs\n",
    "    for h in purge_hucs:\n",
    "        ind = np.where(uniques==h)\n",
    "        uniques = np.delete(uniques, ind)\n",
    "    axis = axisdict[k]\n",
    "\n",
    "    yfhucdict = {}\n",
    "    yfvalues = []\n",
    "    skiphuc = []\n",
    "    for j, cat_val in enumerate(uniques):  # each HUC ID\n",
    "        yfmoddict = {}\n",
    "        for i, md in enumerate(modlist):  # each of the 3 FWP models\n",
    "            df = dfdict[md].loc[dfdict[md][each]==cat_val]\n",
    "            if df.rt.count() >= minptl:\n",
    "                youngdf = df.loc[df.rt < 65]\n",
    "                yf = youngdf.rt.count() / df.rt.count()\n",
    "                yfmoddict[md] = yf\n",
    "                yfvalues.append(yf)\n",
    "            else:\n",
    "                skiphuc.append(cat_val)\n",
    "                break\n",
    "        if cat_val not in skiphuc:\n",
    "            yfhucdict[cat_val] = yfmoddict    \n",
    "\n",
    "    ddd = pd.DataFrame(yfhucdict).T\n",
    "    r2_y1 = r2_score(np.array(ddd[x1]), np.array(ddd[y1]))\n",
    "    r2_y2 = r2_score(np.array(ddd[x1]), np.array(ddd[y2]))\n",
    "    \n",
    "    #plotting\n",
    "    mini, maxi = min(yfvalues), max(yfvalues)\n",
    "    #xplot = mini+(maxi-mini)/2\n",
    "    yrange = maxi-mini\n",
    "    if k == 0:\n",
    "        ddd.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', label='1-layer zoned K', ax=axis)\n",
    "        ddd.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', label = '5-layer zoned K', ax=axis)\n",
    "        axis.text(mini, mini+0.88*yrange, 'R2 = {:3.3f}'.format(r2_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.83*yrange, 'R2 = {:3.3f}'.format(r2_y2), fontsize=9, color='blue')\n",
    "    else:\n",
    "        ddd.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', ax=axis)\n",
    "        ddd.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', ax=axis)\n",
    "        axis.text(mini, mini+yrange, 'R2 = {:3.3f}'.format(r2_y1), fontsize=9, color='green')\n",
    "        axis.text(mini, mini+0.95*yrange, 'R2 = {:3.3f}'.format(r2_y2), fontsize=9, color='blue')\n",
    "    \n",
    "    axis.plot((mini, maxi), (mini, maxi), 'k--')\n",
    "    axis.set_xlabel(''), axis.set_ylabel('')\n",
    "    axis.set_title(each)\n",
    "    \n",
    "    # Add an attribute to the HUC shapefile\n",
    "    #shapefile = HUCshpdict[each]\n",
    "    #shp = gpd.read_file(shapefile)  \n",
    "    #shp[each] = shp[each].astype('int64')  # convert so can merge\n",
    "    ddd.index = ddd.index.astype('int64')  # convert so can merge\n",
    "    ddd['YF_hK-1L'] = ddd[x1] - ddd[y1]\n",
    "    ddd['YF_hK-zK'] = ddd[x1] - ddd[y2]\n",
    "\n",
    "    #df = pd.merge(shp, ddd, how='outer', left_on=each, right_index=True)\n",
    "    #dst = shapefile[:-4] + '_YF.shp'\n",
    "    #df.to_file(dst)\n",
    "\n",
    "fig.text(0.5, 0.06, 'Fraction of young water (<65 yr) in the complex model', ha='center')\n",
    "fig.text(0.06, 0.48, 'Fraction of young water (<65 yr) in the simple models', va='center', rotation='vertical')\n",
    "plt.subplots_adjust(top = .9)\n",
    "fig.suptitle('Comparison of glacial aquifer\\n young fractions by HUCs', fontsize=14)\n",
    "\n",
    "#dst = 'YFrac_glac_121_allHUCs'\n",
    "#loc = os.path.dirname(path[modlist[0]])  # go up one directory to the dir that houses all of the models.\n",
    "#dst_pth = os.path.join(loc, dst)\n",
    "#plt.savefig(dst_pth)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 plot of meanYoungAge and meanOldAge btwn 5LhK against 1L and 5LzK models for select HUC scale.\n",
    "\n",
    "\n",
    "# make sure we get ALL unique HUC IDs\n",
    "u1 = dfdict[modlist[0]][category].unique()\n",
    "u2 = dfdict[modlist[1]][category].unique()\n",
    "u3 = dfdict[modlist[2]][category].unique()\n",
    "u = np.append(u1, u2)\n",
    "u = np.append(u, u3)\n",
    "uniques = np.unique(u)\n",
    "# remove any HUCs listed in purge_hucs\n",
    "for h in purge_hucs:\n",
    "    ind = np.where(uniques==h)\n",
    "    uniques = np.delete(uniques, ind)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10, 4.6))\n",
    "\n",
    "skiphuc = []\n",
    "yfhucdict = {}\n",
    "yfvalues = []\n",
    "ofhucdict = {}\n",
    "ofvalues = []\n",
    "for j, cat_val in enumerate(uniques):  # each HUC ID\n",
    "    yfmoddict = {}\n",
    "    ofmoddict = {}\n",
    "    for i, md in enumerate(modlist):  # each of the 3 FWP models\n",
    "        df = dfdict[md].loc[dfdict[md][category]==cat_val]\n",
    "        if df.rt.count() >= minptl:\n",
    "            youngdf = df.loc[df.rt < 65]\n",
    "            olddf = df.loc[df.rt >= 65]\n",
    "            yfage = youngdf.rt.median()\n",
    "            ofage = olddf.rt.median()\n",
    "            yfmoddict[md] = yfage\n",
    "            yfvalues.append(yfage) \n",
    "            ofmoddict[md] = ofage\n",
    "            ofvalues.append(ofage)\n",
    "        else:\n",
    "            skiphuc.append(cat_val)\n",
    "            break\n",
    "    if cat_val not in skiphuc:\n",
    "        yfhucdict[cat_val] = yfmoddict\n",
    "        ofhucdict[cat_val] = ofmoddict\n",
    "        \n",
    "young = pd.DataFrame(yfhucdict).T\n",
    "old = pd.DataFrame(ofhucdict).T\n",
    "r2_y1y = r2_score(np.array(young[x1]), np.array(young[y1]))\n",
    "r2_y2y = r2_score(np.array(young[x1]), np.array(young[y2]))\n",
    "r2_y1o = r2_score(np.array(old[x1]), np.array(old[y1]))\n",
    "r2_y2o = r2_score(np.array(old[x1]), np.array(old[y2]))\n",
    "\n",
    "#plotting\n",
    "miny, maxy = min(yfvalues), max(yfvalues)\n",
    "mino, maxo = min(ofvalues), max(ofvalues)\n",
    "xplot = mini+(maxi-mini)/2\n",
    "yrange_y = maxy-miny\n",
    "yrange_o = maxo-mino\n",
    "\n",
    "young.plot(kind='scatter', x=x1, y=y1, marker='o', c='green', label='1-layer zoned K', ax=ax1)\n",
    "young.plot(kind='scatter', x=x1, y=y2, marker='^', c='blue', label='5-layer zoned K', ax=ax1)\n",
    "old.plot(kind='scatter', x=x1, y=y1, marker='o', c='green', ax=ax2)\n",
    "old.plot(kind='scatter', x=x1, y=y2, marker='^', c='blue', ax=ax2)\n",
    "ax1.text(miny, miny+0.80*yrange_y, 'R2 = {:3.3f}'.format(r2_y1y), fontsize=9, color='green')\n",
    "ax1.text(miny, miny+0.75*yrange_y, 'R2 = {:3.3f}'.format(r2_y2y), fontsize=9, color='blue')\n",
    "ax2.text(mino, mino+yrange_o, 'R2 = {:3.3f}'.format(r2_y1o), fontsize=9, color='green')\n",
    "ax2.text(mino, mino+0.95*yrange_o, 'R2 = {:3.3f}'.format(r2_y2o), fontsize=9, color='blue')\n",
    "ax1.plot((miny, maxy), (miny, maxy), 'k--')\n",
    "ax2.plot((mino, maxo), (mino, maxo), 'k--')\n",
    "ax1.set_xlabel(''), ax1.set_ylabel(''), ax2.set_ylabel(''), ax2.set_xlabel('')\n",
    "fig.text(0.25, 0.82, 'Young fraction')\n",
    "fig.text(0.73, 0.82, 'Old fraction', ha='center')\n",
    "fig.text(0.07, 0.45, 'Median age (yrs) for the simpler models', va='center', rotation='vertical')\n",
    "fig.text(0.5, 0.01, 'Median age (yrs) for the complex model', ha='center')\n",
    "plt.subplots_adjust(top = .8)\n",
    "fig.suptitle('Comparison of median ages for young and\\n old water in the glacial aquifer by {}'.format(category), fontsize=14)\n",
    "#fig.tight_layout()\n",
    "\n",
    "#dst = 'YnOages_121_{}'.format(category)\n",
    "#loc = os.path.dirname(path[modlist[0]])  # should go up one directory to the dir that houses all of the models.\n",
    "#dst_pth = os.path.join(loc, dst)\n",
    "#plt.savefig(dst_pth)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 plot of meanYoungAge and meanOldAge btwn 5LhK against 1L and 5LzK models for ALL HUC scales.\n",
    "\n",
    "hucs = ['HUC6', 'HUC8', 'HUC10', 'HUC12']\n",
    "nhucs = len(hucs)\n",
    "fig, [[ax1, ax2, ax3, ax4], [ax5, ax6, ax7, ax8]] = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))\n",
    "youngaxisdict = {0:ax1, 1:ax2, 2:ax5, 3:ax6}\n",
    "oldaxisdict = {0:ax3, 1:ax4, 2:ax7, 3:ax8}\n",
    "\n",
    "for k, each in enumerate(hucs):\n",
    "    # make sure we get ALL unique HUC IDs\n",
    "    u1 = dfdict[modlist[0]][each].unique()\n",
    "    u2 = dfdict[modlist[1]][each].unique()\n",
    "    u3 = dfdict[modlist[2]][each].unique()\n",
    "    u = np.append(u1, u2)\n",
    "    u = np.append(u, u3)\n",
    "    uniques = np.unique(u)\n",
    "    # remove any HUCs listed in purge_hucs\n",
    "    for h in purge_hucs:\n",
    "        ind = np.where(uniques==h)\n",
    "        uniques = np.delete(uniques, ind)\n",
    "    youngaxis = youngaxisdict[k]\n",
    "    oldaxis = oldaxisdict[k]\n",
    "    ofhucdict = {}\n",
    "    yfhucdict = {}\n",
    "    yfvalues = []\n",
    "    ofvalues = []\n",
    "    skiphuc = []\n",
    "    for j, cat_val in enumerate(uniques):  # each HUC ID\n",
    "        yfmoddict = {} \n",
    "        ofmoddict = {} \n",
    "        for i, md in enumerate(modlist):  # each of the 3 FWP models\n",
    "            df = dfdict[md].loc[dfdict[md][each]==cat_val]\n",
    "            if df.rt.count() >= minptl:\n",
    "                youngdf = df.loc[df.rt < 65]\n",
    "                olddf = df.loc[df.rt >= 65]\n",
    "                yfage = youngdf.rt.median()\n",
    "                ofage = olddf.rt.median()\n",
    "                yfmoddict[md] = yfage\n",
    "                yfvalues.append(yfage) \n",
    "                ofmoddict[md] = ofage\n",
    "                ofvalues.append(ofage)\n",
    "                # pull out raw time info for generalized model areas for later use...\n",
    "                if (cat_val == float(genHUCdict['Oconto'])) and ('fwp5lzk' in md):  # 5lzK is the most similar to Generalized models\n",
    "                    FWPzKocontoDF = df.copy()\n",
    "                #elif cat_val == float(genHUCdict['TWR'])  and (md == 'fwp5lzk'):\n",
    "                elif cat_val == float(genHUCdict['TWR'])  and ('fwp5lzk' in md):\n",
    "                    FWPzKtwrDF = df.copy()\n",
    "                elif (cat_val == float(genHUCdict['Oconto'])) and ('fwp5lhk' in md):  # 5lzK is the most similar to Generalized models\n",
    "                    FWPhKocontoDF = df.copy()\n",
    "                elif cat_val == float(genHUCdict['TWR'])  and ('fwp5lhk' in md):\n",
    "                    FWPhKtwrDF = df.copy()\n",
    "                elif (cat_val == float(genHUCdict['Oconto'])) and ('fwp1l' in md):  # 5lzK is the most similar to Generalized models\n",
    "                    FWP1locontoDF = df.copy()\n",
    "                elif cat_val == float(genHUCdict['TWR'])  and ('fwp1l' in md):\n",
    "                    FWP1ltwrDF = df.copy()                    \n",
    "            else:\n",
    "                skiphuc.append(cat_val)\n",
    "                break\n",
    "        if cat_val not in skiphuc:\n",
    "            yfhucdict[cat_val] = yfmoddict\n",
    "            ofhucdict[cat_val] = ofmoddict            \n",
    "            \n",
    "    young = pd.DataFrame(yfhucdict).T\n",
    "    old = pd.DataFrame(ofhucdict).T\n",
    "    for n in modlist:\n",
    "        young = young.loc[~young[n].isnull()]  # need to remove any NANs\n",
    "        old = old.loc[~old[n].isnull()]  # need to remove any NANs\n",
    "    r2_y1y = r2_score(np.array(young[x1]), np.array(young[y1]))\n",
    "    r2_y2y = r2_score(np.array(young[x1]), np.array(young[y2]))\n",
    "    r2_y1o = r2_score(np.array(old[x1]), np.array(old[y1]))\n",
    "    r2_y2o = r2_score(np.array(old[x1]), np.array(old[y2]))\n",
    "    \n",
    "    #plotting\n",
    "    miny, maxy = min(yfvalues), max(yfvalues)\n",
    "    mino, maxo = min(ofvalues), max(ofvalues)\n",
    "    #xplot = mini+(maxi-mini)/2\n",
    "    yrange_y = maxy-miny\n",
    "    yrange_o = maxo-mino\n",
    "    \n",
    "    if k == 0:\n",
    "        young.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', label='1-layer zoned K', ax=youngaxis)\n",
    "        young.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', label = '5-layer zoned K', ax=youngaxis)        \n",
    "        old.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', ax=oldaxis)\n",
    "        old.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', ax=oldaxis)  \n",
    "    else:\n",
    "        young.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', ax=youngaxis)\n",
    "        young.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', ax=youngaxis)\n",
    "        old.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', ax=oldaxis)\n",
    "        old.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', ax=oldaxis)  \n",
    "        \n",
    "    youngaxis.text(miny, miny+yrange_y, 'R2 = {:3.3f}'.format(r2_y1y), fontsize=9, color='green')\n",
    "    youngaxis.text(miny, miny+0.95*yrange_y, 'R2 = {:3.3f}'.format(r2_y2y), fontsize=9, color='blue')\n",
    "    oldaxis.text(mino, mino+yrange_o, 'R2 = {:3.3f}'.format(r2_y1o), fontsize=9, color='green')\n",
    "    oldaxis.text(mino, mino+0.95*yrange_o, 'R2 = {:3.3f}'.format(r2_y2o), fontsize=9, color='blue')\n",
    "    youngaxis.plot((miny, maxy), (miny, maxy), 'k--')\n",
    "    oldaxis.plot((mino, maxo), (mino, maxo), 'k--')\n",
    "\n",
    "    youngaxis.set_xlabel(''), youngaxis.set_ylabel(''), oldaxis.set_xlabel(''), oldaxis.set_ylabel('')\n",
    "    youngaxis.set_title(each)\n",
    "    oldaxis.set_title(each)\n",
    "    \n",
    "    # Add an attribute to the HUC shapefile\n",
    "    #shapefile = HUCshpdict[each]\n",
    "    #shp = gpd.read_file(shapefile)  \n",
    "    #shp[each] = shp[each].astype('int64')  # convert so can merge\n",
    "    \n",
    "    young.index = young.index.astype('int64')  # convert so can merge\n",
    "    young['mYage_hK-1L'] = young[x1] - young[y1]\n",
    "    young['mYage_hK-zK'] = young[x1] - young[y2]\n",
    "    #df = pd.merge(shp, young, how='outer', left_on=each, right_index=True)\n",
    "    #dst = shapefile[:-4] + '_mYage.shp'\n",
    "    #df.to_file(dst)\n",
    "    \n",
    "    old.index = old.index.astype('int64')  # convert so can merge\n",
    "    old['mOage_hK-1L'] = old[x1] - old[y1]\n",
    "    old['mOage_hK-zK'] = old[x1] - old[y2]\n",
    "    #dfo = pd.merge(shp, old, how='outer', left_on=each, right_index=True)\n",
    "    #dsto = shapefile[:-4] + '_mOage.shp'\n",
    "    #dfo.to_file(dsto)\n",
    "\n",
    "fig.text(0.28, 0.92, 'Young fraction', fontsize=12)\n",
    "fig.text(0.71, 0.92, 'Old fraction', ha='center', fontsize=12)\n",
    "fig.text(0.5, 0.055, 'Median age (yrs) for the complex model', ha='center', fontsize=12)\n",
    "fig.text(0.095, 0.48, 'Median age (yrs) for the simpler models', va='center', fontsize=12, rotation='vertical')\n",
    "plt.subplots_adjust(top = .89)\n",
    "fig.suptitle('Comparison of median ages for young and old water in the glacial aquifer by HUCs', fontsize=16)\n",
    "\n",
    "# add background color\n",
    "youngrect = patches.Rectangle((200,70), 760, 830, zorder=-1, alpha=0.5, facecolor='b')\n",
    "oldrect = patches.Rectangle((960,70), 780, 830, zorder=-1, alpha=0.5, facecolor='r')\n",
    "fig.patches.append(youngrect)\n",
    "fig.patches.append(oldrect)\n",
    "\n",
    "#dst = 'YnOages_121_allHUCs'\n",
    "#loc = os.path.dirname(path[modlist[0]])  # go up one directory to the dir that houses all of the models.\n",
    "#dst_pth = os.path.join(loc, dst)\n",
    "#plt.savefig(dst_pth)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 plot of meanYoungAge btwn 5LhK and 5LzK models for all HUC scales; color coded by differences in parameter\n",
    "# values among the 5LhK and 5LzK models.  What's causing the age differences?\n",
    "\n",
    "metric = 'mean'  # valid:  'mean', 'min', 'max', 'range', 'std'\n",
    "\n",
    "hucs = ['HUC6', 'HUC8', 'HUC10', 'HUC12']\n",
    "nhucs = len(hucs)\n",
    "#fig, [[ax1, ax2], [ax3, ax4]] = plt.subplots(nrows=2, ncols=2, figsize=(9, 9))\n",
    "#axisdict = {0:ax1, 1:ax2, 2:ax3, 3:ax4}\n",
    "\n",
    "# loop this thing\n",
    "for prop in HUCproprastlist:\n",
    "    fig, [[ax1, ax2], [ax3, ax4]] = plt.subplots(nrows=2, ncols=2, figsize=(9, 9))\n",
    "    axisdict = {0:ax1, 1:ax2, 2:ax3, 3:ax4}\n",
    "    \n",
    "    for k, each in enumerate(hucs):\n",
    "        # make sure we get ALL unique HUC IDs\n",
    "        u1 = dfdict[modlist[0]][each].unique()\n",
    "        u2 = dfdict[modlist[1]][each].unique()\n",
    "        u3 = dfdict[modlist[2]][each].unique()\n",
    "        u = np.append(u1, u2)\n",
    "        u = np.append(u, u3)\n",
    "        uniques = np.unique(u)\n",
    "        # remove any HUCs listed in purge_hucs\n",
    "        for h in purge_hucs:\n",
    "            ind = np.where(uniques==h)\n",
    "            uniques = np.delete(uniques, ind)\n",
    "        axis = axisdict[k]\n",
    "\n",
    "        yfhucdict = {}\n",
    "        yfvalues = []\n",
    "        skiphuc = []\n",
    "        for j, cat_val in enumerate(uniques.astype('int64')):  # each HUC ID\n",
    "            yfmoddict = {}\n",
    "            for i, md in enumerate(modlist):  # each of the 3 FWP models\n",
    "                df = dfdict[md].loc[dfdict[md][each]==cat_val]\n",
    "                if df.rt.count() >= minptl:\n",
    "                    youngdf = df.loc[df.rt < 65]\n",
    "                    yfage = youngdf.rt.median()\n",
    "                    yfmoddict[md] = yfage\n",
    "                    yfvalues.append(yfage)\n",
    "                else:\n",
    "                    skiphuc.append(cat_val)\n",
    "                    break\n",
    "            if cat_val not in skiphuc:\n",
    "                yfhucdict[cat_val] = yfmoddict    \n",
    "\n",
    "        ddd = pd.DataFrame(yfhucdict).T\n",
    "        for n in modlist:\n",
    "            ddd = ddd.loc[~ddd[n].isnull()]  # need to remove any NANs\n",
    "\n",
    "        ddd[metric] = 0\n",
    "        r2_y2 = r2_score(np.array(ddd[x1]), np.array(ddd[y2]))  #x1 = 5LheteroK; y2 = 5LzonedK\n",
    "\n",
    "        print('Extracting zonal mean values from {} for {}'.format(prop, each))\n",
    "\n",
    "        # run zonal_stats on the merged df. Use the 'HUC' Tiffs to match up with model properties\n",
    "        raster_file = HUCtiffdict[each]\n",
    "        with rasterio.open(raster_file) as raster:\n",
    "            hucrast = raster.read()[0]\n",
    "        #with rasterio.open(HUCproprast) as raster:\n",
    "        with rasterio.open(prop) as raster:\n",
    "            proprast = raster.read()[0]\n",
    "\n",
    "        # Now pull out summary statistics for overlapping areas\n",
    "        u = np.unique(hucrast)\n",
    "        # Use a cross-reference approach for HUC10 and 12 cuz large INTs mess everything up!\n",
    "        if max(u) < 10000:  # Less than any HUC6 ID number\n",
    "            with open(raster_file.split('.')[0] + '_crossref.txt', mode='r') as infile:\n",
    "                reader = csv.reader(infile)\n",
    "                next(reader, None)  # skip the headers\n",
    "                crossdict = {int(rows[0]):np.int64(rows[1]) for rows in reader}\n",
    "        for ID in u[u>0]:  # HUC IDs in active part of model (not ID zero)\n",
    "            idarr = np.zeros_like(hucrast)\n",
    "            idarr[hucrast==ID] = 1\n",
    "            # multiply by proprast, compute ave, min, max, range, std (median)\n",
    "            hucprop = idarr * proprast\n",
    "            hucprop[hucprop==0] = np.nan\n",
    "            pmn, pmin, pmax, pstd = np.nanmean(hucprop), np.nanmin(hucprop), np.nanmax(hucprop), np.nanstd(hucprop)\n",
    "            prange = pmax - pmin\n",
    "            metricdict = {'mean':pmn, 'min':pmin, 'max':pmax, 'range':prange, 'std':pstd}\n",
    "            if max(u) < 10000:\n",
    "                ddd[metric].loc[ddd.index==crossdict[ID]] = metricdict[metric].astype('float64')  # assigned the appropriate zonal data            \n",
    "            else:\n",
    "                ddd[metric].loc[ddd.index==ID] = metricdict[metric].astype('float64')  # assigned the appropriate zonal data\n",
    "\n",
    "        #plotting\n",
    "        mini, maxi = min(yfvalues), max(yfvalues)\n",
    "        xplot = mini+(maxi-mini)/2\n",
    "        yrange = maxi-mini\n",
    "        #if k == 0:\n",
    "        #    ddd.plot(kind='scatter', x=x1, y=y2, marker='^', c=ddd[metric], cmap='viridis', label = '5-layer zoned K', ax=axis)\n",
    "        #    axis.text(mini, mini+0.83*yrange, 'R2 = {:3.3f}'.format(r2_y2), fontsize=9)\n",
    "        #else:\n",
    "\n",
    "        ddd.plot(kind='scatter', x=x1, y=y2, marker='^', c=ddd[metric], cmap='viridis', ax=axis)  # How center on Zero?\n",
    "        axis.text(mini, mini+0.95*yrange, 'R2 = {:3.3f}'.format(r2_y2), fontsize=9)\n",
    "        pos1 = axis.get_position()\n",
    "        axis.plot((mini, maxi), (mini, maxi), 'k--')\n",
    "        axis.set_xlabel(''), axis.set_ylabel('')\n",
    "        axis.set_title(each)\n",
    "\n",
    "    fig.text(0.48, 0.89, 'Young fraction', fontsize=12)\n",
    "    fig.text(0.5, 0.105, 'Median age (yrs) for the 5-layer variable K model', ha='center', fontsize=12)\n",
    "    fig.text(0.07, 0.48, 'Median age (yrs) for the 5-layer zoned K model', va='center', fontsize=12, rotation='vertical')\n",
    "    plt.subplots_adjust(top = .86, bottom = 0.15)\n",
    "    #mod_factor = os.path.basename(HUCproprast).split('.')[0]\n",
    "    mod_factor = os.path.basename(prop).split('.')[0]\n",
    "    fig.suptitle('Comparison of median Glacial Young ages by HUC scale,\\n as informed by model '\n",
    "                 'property:  {} of {}'.format(metric, mod_factor), fontsize=16)\n",
    "\n",
    "#    dst = '5L_mYageCompare_by_{}_of_{}.png'.format(metric, mod_factor)\n",
    "#    loc = os.path.dirname(path[modlist[0]])  # go up one directory to the dir that houses all of the models.\n",
    "#    dst_pth = os.path.join(loc, dst)\n",
    "    #plt.savefig(dst_pth)\n",
    "#    f = plt.gcf()\n",
    "#    f.savefig(dst_pth)\n",
    "    #[f.get_axes()[4].remove() for x in range(4,8)] # remove the colorbars\n",
    "#f.close()\n",
    "#fig.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set user-defined variables\n",
    "\n",
    "MODFLOW and MODPATH use elapsed time and are not aware of calendar time. To place MODFLOW/MODPATH elapsed time on the calendar, two calendar dates were specified at the top of the notebook: the beginning of the first stress period (`mf_start_date`) and when particles are to be released (`mp_release_date`). The latter date could be used in many ways, for example to represent a sampling date, or it could be looped over to create a time-lapse set of ages. \n",
    "\n",
    "### Required: Populate the simulate_list and categories lists.  Also be sure to specify which category to evaluate. Note that categories that are small (lots of individual areas within the model domain) will make plotting VERY slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through home directory to get list of name files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create names and path for model workspace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedures in this notebook can be run from the notebook or from a batch file by downloading the notebook as a Python script and uncommenting the following code and commenting out the following block. The remainder of the script has to be indented to be included in the loop.  This may require familiarity with Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load an existing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification of time in MODFLOW/MODPATH\n",
    "\n",
    "There are several time-related concepts used in MODPATH.\n",
    "* `simulation time` is the elapsed time in model time units from the beginning of the first stress period\n",
    "* `reference time` is an arbitrary value of `simulation time` that is between the beginning and ending of `simulation time`\n",
    "* `tracking time` is the elapsed time relative to `reference time`. It is always positive regardless of whether particles are tracked forward or backward\n",
    "* `release time` is when a particle is released and is specified in `tracking time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# setup dictionaries of the MODFLOW units for proper labeling of figures.\n",
    "lenunit = {0:'undefined units', 1:'feet', 2:'meters', 3:'centimeters'}\n",
    "timeunit = {0:'undefined', 1:'second', 2:'minute', 3:'hour', 4:'day', 5:'year'}\n",
    "\n",
    "# Create dictionary of multipliers for converting model time units to days\n",
    "time_dict = dict()\n",
    "time_dict[0] = 1.0 # undefined assumes days, so enter conversion to days\n",
    "time_dict[1] = 24 * 60 * 60\n",
    "time_dict[2] = 24 * 60\n",
    "time_dict[3] = 24\n",
    "time_dict[4] = 1.0\n",
    "time_dict[5] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# convert string representation of dates into Python datetime objects\n",
    "mf_start_date = dt.datetime.strptime(mf_start_date_str , '%m/%d/%Y')\n",
    "mp_release_date = dt.datetime.strptime(mp_release_date_str , '%m/%d/%Y')\n",
    "\n",
    "# convert simulation time to days from the units specified in the MODFLOW DIS file\n",
    "sim_time = np.append(0, dis.get_totim())\n",
    "sim_time /= time_dict[dis.itmuni]\n",
    "\n",
    "# make a list of simulation time formatted as calendar dates\n",
    "date_list = [mf_start_date + dt.timedelta(days = item) for item in sim_time]\n",
    "\n",
    "# reference time and date are set to the end of the last stress period\n",
    "ref_time = sim_time[-1]\n",
    "ref_date = date_list[-1]\n",
    "\n",
    "# release time is calculated in tracking time (for particle release) and \n",
    "# in simulation time (for identifying head and budget components)\n",
    "release_time_trk = np.abs((ref_date - mp_release_date).days)\n",
    "release_time_sim = (mp_release_date - mf_start_date).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
