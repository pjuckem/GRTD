{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script loads pickles of EPT files, calculates YF and median age YF, then makes 1:1 plots to compare simplified models to the most complex model.  The goal is to evaluate if and how complexity influences age metrics across scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This version is slightly altered to limit the analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The script reads in the model_grid.csv file for each model and uses that to tie each particle's initial location to select categories, such as the HUC, NLCD, coarse fraction, etc.  The model_grid.csv file was created via verion 2 of the general models / GRTD notebooks, tied to PFJ's repo called \"GenMod\" on the USGS GitLab site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'Paul Juckem'\n",
    "%matplotlib notebook\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "from datetime import datetime\n",
    "import gdal\n",
    "from gdal import ogr, osr\n",
    "import gen_mod_functions as gm\n",
    "import flopy as fp\n",
    "import pickle\n",
    "from ipywidgets import interact, Dropdown, Text\n",
    "from IPython.display import display\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import csv\n",
    "\n",
    "import fit_parametric_distributions\n",
    "\n",
    "try:\n",
    "    import rasterio\n",
    "except:\n",
    "    print('Install rasterio into your python environment. Or, skip plotting of geotiffs at the end of this notebook')\n",
    "\n",
    "modifier = False\n",
    "def ReturnEntry(sender):\n",
    "    modifier.value = intext.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify user input, including list of models to compare and which axes to plot them, plus attributes to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulate_list = ['FWP1L_zK', 'FWP5L_zK', 'FWP5L_hK']  # list of models (w/ matching directory name) to analyze\n",
    "simulate_list = ['FWP5L_hK']\n",
    "\n",
    "# This variable facilitates scenario testing (stopping or not at weak sinks/sources; porosity values & configuration, etc.)\n",
    "#scenario_name = None  # set to None if no additional text was added to the modpath file names.\n",
    "#scenario_name = 'passthroughsnk'  # an optional text string added to MP file names. MUST match value used in NB 01aa!!!\n",
    "scenario_name = 'het_n'  \n",
    "\n",
    "# when comparing results of the scenario to the base case, which weighting option to use? 'flux' or 'volume'\n",
    "base_case = 'flux'\n",
    "\n",
    "# for plotting 1:1 graphs\n",
    "x1, y1 = 0, 1  # index of names in the yet-to-be-populated eptlist variable.  (0=base case; 1 = scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_aq_lays = 3  # deepest layer of the surficial aquifer.\n",
    "\n",
    "nrow, ncol = 930, 650  # easier to hardcode this than waste the time to read-in a model just to get DIS info.\n",
    "\n",
    "# for labeling RTD plots\n",
    "label_by_model_name = True  # if false, will include zone info in label.\n",
    "\n",
    "category = 'HUC12' \n",
    "\n",
    "minptl = 500  # The minimum number of particles for EACH model within each HUC (eg: if FWP5L has 2000, \n",
    "               # but FWP1L has 800, none get plotted in the 1:1 plots.  Still included in the RTD plots.)\n",
    "               # 500-1000 seems reasonable for 1:1 plots as it includes only HUCs with really refined RTDs;\n",
    "               # however, 100 - 500 seems more reasonable if we want to visualize spatial patterns because it\n",
    "               # allows more HUCs to be plotted.  100-500 is based on visually inspecting RTD curves.\n",
    "                \n",
    "# Columns in the model_grid.csv file to keep.  Purge all others.\n",
    "mg_columns = ['node_num', 'row', 'col', 'HUC6', 'HUC8', 'HUC10', 'HUC12', 'ibound', 'gage_id', 'coarse_flag', \n",
    "              'qu_atlas', 'catchment', 'ssurgo', 'stream_order', 'surfmat']\n",
    "                \n",
    "purge_hucs = [40602, 4060200, 406020000, 40602000000]  # all hucs for Lake Michigan      \n",
    "\n",
    "HUCshpdict = {'HUC6':'E:/HUCS/WBD_4n7/WBD_HUC6_UTMft_FWPdomain.shp', \n",
    "              'HUC8':'E:/HUCS/WBD_4n7/WBD_HUC8_UTMft_FWPdomain.shp', \n",
    "              'HUC10':'E:/HUCS/WBD_4n7/WBD_HUC10_UTMft_FWPdomain.shp', \n",
    "              'HUC12':'E:/HUCS/WBD_4n7/WBD_HUC12_UTMft_FWPdomain.shp'}\n",
    "\n",
    "HUCtiffdict = {'HUC6':'E:/HUCS/WBD_4n7/HUC6_UTMft_FWP.tiff', \n",
    "              'HUC8':'E:/HUCS/WBD_4n7/HUC8_UTMft_FWP.tiff', \n",
    "              'HUC10':'E:/HUCS/WBD_4n7/HUC10_UTMft_FWP.tiff',\n",
    "              'HUC12':'E:/HUCS/WBD_4n7/HUC12_UTMft_FWP.tiff'}\n",
    "\n",
    "#HUCproprast = './vK_lay1_hK-vK.tif'\n",
    "HUCproprastlist = ['../TIFFs/vK_lay1_5h-5z.tif', '../TIFFs/vK_lay2_5h-5z.tif', '../TIFFs/vK_lay3_5h-5z.tif', '../TIFFs/vK_lay1_hK-vK.tif',\n",
    "                 '../TIFFs/vani_lay1_5h-5z.tif', '../TIFFs/vani_lay2_5h-5z.tif', '../TIFFs/vani_lay3_5h-5z.tif',\n",
    "                 '../TIFFs/T_lay1_5h-5z.tif', '../TIFFs/T_lay2_5h-5z.tif', '../TIFFs/T_lay3_5h-5z.tif', '../TIFFs/GlacT_5h-5z.tif',\n",
    "                 '../TIFFs/glac_satthick_5h-5z.tif', '../TIFFs/BrRCH_5h-5z.tif', '../TIFFs/RCH_5h-5z.tif', \n",
    "                 '../TIFFs/hK_lay1_5h-5z.tif', '../TIFFs/hK_lay2_5h-5z.tif', '../TIFFs/hK_lay3_5h-5z.tif',\n",
    "                 '../TIFFs/BrT_5h-5z.tif', '../TIFFs/glacT2BrT_5h-5z.tif', '../TIFFs/RCHUZF_5h-5z.tif', '../TIFFs/UZF_5h-5z.tif', \n",
    "                 '../TIFFs/RCHcbb_5h-5z.tif', '../TIFFs/rch-over-satKs_5h-5z.tif', '../TIFFs/sat-weighted_Ks_5h-5z.tif']\n",
    "HUCfluxrastlist = ['../TIFFs/SWleak_5h-5z.tif', '../TIFFs/MNW2_5h-5z.tif', '../TIFFs/SFR_5h-5z.tif']\n",
    "genHUCdict = {'Oconto':'04030104', 'TWR':'0403020218'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep the script for the models to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homes = ['../Models']\n",
    "fig_dir = '../Figures'\n",
    "\n",
    "if not os.path.exists(fig_dir):\n",
    "    os.mkdir(fig_dir)\n",
    "\n",
    "mfpth = '../executables/MODFLOW-NWT_1.0.9/bin/MODFLOW-NWT_64.exe'\n",
    "mp_exe_name = '../executables/modpath.6_0/bin/mp6x64.exe' \n",
    "\n",
    "age_cutoff = 65\n",
    "#year_cutoff = '01/01/1952'\n",
    "\n",
    "surf_aq_lays = 3  # deepest layer of the surficial aquifer.\n",
    "\n",
    "dir_list = []\n",
    "modlist = []\n",
    "i = 0\n",
    "r = 0\n",
    "\n",
    "path_dict = {}\n",
    "dfdict = {}\n",
    "totp = {}\n",
    "for home in homes:\n",
    "    if os.path.exists(home):\n",
    "        for dirpath, dirnames, filenames in os.walk(home):\n",
    "            for f in filenames:\n",
    "                if os.path.splitext(f)[-1] == '.nam':\n",
    "                    mod = os.path.splitext(f)[0]\n",
    "                    i += 1\n",
    "                    if mod in simulate_list:\n",
    "                        modlist.append(mod)\n",
    "                        dir_list.append(dirpath)\n",
    "                        r += 1\n",
    "                        path_dict[mod] = dirpath\n",
    "                               \n",
    "print('    {} models read'.format(i))\n",
    "print('These {} models will be analyzed: {}'.format(r, modlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list of nam files:\n",
    "nam_list = []\n",
    "for pth in dir_list:\n",
    "    model = os.path.normpath(pth).split(os.sep)[2]\n",
    "    nam_file = '{}.nam'.format(model)\n",
    "    nam_list.append(nam_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup dictionaries of the MODFLOW units for proper labeling of figures.\n",
    "lenunit = {0:'undefined units', 1:'feet', 2:'meters', 3:'centimeters'}\n",
    "timeunit = {0:'undefined', 1:'second', 2:'minute', 3:'hour', 4:'day', 5:'year'}\n",
    "\n",
    "# Create dictionary of multipliers for converting model time units to days\n",
    "time_dict = dict()\n",
    "time_dict[0] = 1.0 # undefined assumes days, so enter conversion to days\n",
    "time_dict[1] = 24 * 60 * 60\n",
    "time_dict[2] = 24 * 60\n",
    "time_dict[3] = 24\n",
    "time_dict[4] = 1.0\n",
    "time_dict[5] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read-in model info and check max/min nlay & create list of DIS objects.  \n",
    "# Assumes all else is the same among models (hnoflow, hdry, etc)\n",
    "print ('Reading model information')\n",
    "nlay_min = 100\n",
    "nlay_max = 0\n",
    "\n",
    "dis_objs = []\n",
    "for i, model in enumerate(nam_list):\n",
    "    nam_file = model\n",
    "    model_ws = dir_list[i]\n",
    "    \n",
    "    fpmg = fp.modflow.Modflow.load(nam_file, model_ws=model_ws, exe_name=mfpth, version='mfnwt', \n",
    "                                   load_only=['DIS', 'BAS6', 'UPW', 'OC'], check=False)\n",
    "\n",
    "    dis = fpmg.get_package('DIS')\n",
    "    dis_objs.append(dis)\n",
    "    bas = fpmg.get_package('BAS6')\n",
    "    upw = fpmg.get_package('UPW')\n",
    "    oc = fpmg.get_package('OC')\n",
    "\n",
    "    delr = dis.delr\n",
    "    delc = dis.delc\n",
    "    nlay = dis.nlay\n",
    "    nrow = dis.nrow\n",
    "    ncol = dis.ncol\n",
    "    bot = dis.getbotm()\n",
    "    top = dis.gettop()\n",
    "\n",
    "    hnoflo = bas.hnoflo\n",
    "    ibound = np.asarray(bas.ibound.get_value())\n",
    "    hdry = upw.hdry\n",
    "    \n",
    "    if nlay > nlay_max:\n",
    "        nlay_max = nlay\n",
    "    if nlay < nlay_min:\n",
    "        nlay_min = nlay\n",
    "        \n",
    "    print('  .. done reading model {}'.format(i+1))\n",
    "\n",
    "print ('   ... all done') \n",
    "\n",
    "print('minimum layers in a model:  {}'.format(nlay_min))\n",
    "print('maximum layers in a model:  {}'.format(nlay_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process endpoint files and merge with model_grid.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purge(ep_data):\n",
    "    pre_Quaternary = ep_data.loc[ep_data.rt>=2.6e6]\n",
    "    pre_Cretaceous = ep_data.loc[ep_data.rt>=66e6]\n",
    "    preCambrian = ep_data.loc[ep_data.rt>=541e6]\n",
    "    pre_earth = ep_data.loc[ep_data.rt>=4.6e9]\n",
    "\n",
    "    print('\\nFor your information:')\n",
    "    print('{} particles were simulated as being older than Earth!'.format(preCambrian.shape[0]))\n",
    "    print('{} particles were simulated as being PreCambrian in age.'.format(preCambrian.shape[0]))\n",
    "    print('{} particles were simulated as being Cretaceous in age or older.'.format(pre_Cretaceous.shape[0]))\n",
    "    print('{} particles were simulated as being pre-Quaternary in age.'.format(pre_Quaternary.shape[0]))\n",
    "    \n",
    "    ep_data = ep_data.loc[ep_data.rt<4.6e9]\n",
    "    print('Purged particles older than earth')\n",
    "    return(ep_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read-in the model_grid.csv file for each model.  Then create a dataframe from each csv & pickle file.\n",
    "\n",
    "dfdict = {}\n",
    "totp = {}\n",
    "\n",
    "for i, model in enumerate(modlist):\n",
    "    g = os.path.join(path_dict[model], 'model_grid.csv')\n",
    "    z = os.path.join(path_dict[model], 'zone_df.csv')\n",
    "    try:\n",
    "        df = pd.read_csv(g)\n",
    "        df.ibound.replace(0, np.nan, inplace=True)\n",
    "        df = df[df.ibound.notnull()]\n",
    "        df = df[mg_columns]  # keep just the desired fields\n",
    "        # re-calculate 2D cell number b/c node_num is computed differently for model_grid.csv and what's in the ept file.\n",
    "        df['cellnum2d'] = df.row * ncol + df.col\n",
    "        \n",
    "        zone_df = pd.read_csv(z, index_col=0)\n",
    "        for group in zone_df:\n",
    "            print('\\nReading-in the EPT file for {} in {}'.format(group, model))\n",
    "            if scenario_name == None:\n",
    "                print(\"Oops, I didn't really plan for this.  Stopping\")\n",
    "                sys.exit()\n",
    "            else:\n",
    "                p1 = os.path.join(path_dict[model], '{}_{}_{}.mpend'.format(model, base_case, group))\n",
    "                p2 = os.path.join(path_dict[model], '{}_{}_{}_{}.mpend'.format(model, base_case, group, scenario_name))\n",
    "                mnz1 = '{}_{}'.format(model, group)\n",
    "                mnz2 = '{}_{}_{}'.format(model, group, scenario_name)\n",
    "                eptu1 = fit_parametric_distributions.read_endpoints(p1, dis, time_dict)\n",
    "                eptu2 = fit_parametric_distributions.read_endpoints(p2, dis, time_dict)\n",
    "                \n",
    "            eptu1 = purge(eptu1)\n",
    "            eptu2 = purge(eptu2)\n",
    "            eptu1['cellnum2d'] = (eptu1['Initial Row']-1) * ncol + (eptu1['Initial Column'] -1)  # -1 to convert to 0-based\n",
    "            eptu2['cellnum2d'] = (eptu2['Initial Row']-1) * ncol + (eptu2['Initial Column'] -1)  # -1 to convert to 0-based\n",
    "            eptu1_mg = eptu1.join(df, on='cellnum2d', lsuffix='_ept', rsuffix='_mg')\n",
    "            eptu2_mg = eptu2.join(df, on='cellnum2d', lsuffix='_ept', rsuffix='_mg')\n",
    "            eptu1_mg = eptu1_mg[eptu1_mg['Initial Layer'] <= surf_aq_lays]  # ensure that we're only analyzing Glacial!\n",
    "            eptu2_mg = eptu2_mg[eptu2_mg['Initial Layer'] <= surf_aq_lays]  # ensure that we're only analyzing Glacial!\n",
    "\n",
    "            #dfdict[model] = eptu_mg\n",
    "            dfdict[mnz1] = eptu1_mg\n",
    "            dfdict[mnz2] = eptu2_mg\n",
    "            totp[mnz1] = eptu1_mg.rt.count()\n",
    "            totp[mnz2] = eptu2_mg.rt.count()\n",
    "            \n",
    "            x1 = eptlist[x1]  # pull out the file name after supplying the index\n",
    "            y1 = eptlist[y1]\n",
    "            \n",
    "    except (AttributeError, ValueError, IOError, IndexError):\n",
    "        print('ERROR. THIS CODE BLOCK DID NOT COMPLETE. TROUBLE-SHOOT AND TRY AGAIN')\n",
    "        print('The error occured while working on this model: {}'.format(model))\n",
    "        raise SystemExit()\n",
    "\n",
    "eptlist = list(dfdict.keys())\n",
    "print('....done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eptlist)\n",
    "print(modlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(dfdict[eptlist[0]] == dfdict[eptlist[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot age distributions for all 3 models by HUC ID, for selected HUC scale.\n",
    "\n",
    "#uniques = dfdict[modlist[0]][category].unique()\n",
    "uniques = dfdict[eptlist[0]][category].unique()\n",
    "# remove any HUCs listed in purge_hucs\n",
    "for h in purge_hucs:\n",
    "    ind = np.where(uniques==h)\n",
    "    uniques = np.delete(uniques, ind)\n",
    "\n",
    "n_uni = len(uniques)\n",
    "sum_p = {}\n",
    "for mn in eptlist:\n",
    "    sum_p[mn] = 0\n",
    "    \n",
    "if n_uni <= 20:\n",
    "    vplots = int(np.ceil(n_uni/ 3.0))\n",
    "    figsize = (12, 3*vplots)\n",
    "    CS, CSaxes = plt.subplots(vplots, 3, figsize=figsize)\n",
    "else:\n",
    "    hplots = int(np.round(np.sqrt(n_uni)))\n",
    "    vplots = int(np.ceil(np.sqrt(n_uni)))\n",
    "    figsize = (hplots*4, hplots*3)\n",
    "    CS, CSaxes = plt.subplots(vplots, hplots, figsize=figsize)\n",
    "        \n",
    "colors_line = plt.cm.brg(np.linspace(0, 1, len(eptlist)))\n",
    "\n",
    "for ax, cat_val in zip(CSaxes.flat, uniques):\n",
    "    n = []\n",
    "    for i, md in enumerate(eptlist):\n",
    "        rt = dfdict[md].loc[dfdict[md][category]==cat_val, 'rt']  # 'rt' is \"raw time\" in the dataframe\n",
    "        rt.sort_values(inplace=True)\n",
    "        n.append(rt.count())\n",
    "        sum_p[md] = sum_p[md] + rt.count()\n",
    "        y_rt = np.linspace(0, 1, rt.shape[0])\n",
    "    \n",
    "        if label_by_model_name:\n",
    "            label = eptlist[i]\n",
    "        else:\n",
    "            label = md\n",
    "        ax.plot(rt, y_rt, c=colors_line[i], label=label)\n",
    "        ax.plot((age_cutoff, age_cutoff), (0.2, 1), 'k--')\n",
    "        \n",
    "        title = '{}: {}'.format(category, cat_val)\n",
    "        ax.set_title(title, fontsize=12)\n",
    "\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlim(1e0, 1e3)\n",
    "        ax.set_ylim(0, )\n",
    "\n",
    "        ax.legend(loc=0, frameon=False, fontsize=8)#, bbox_to_anchor=(0.20, 0.2), ncol=1)\n",
    "        ax.set_xlabel('Residence time, in years')\n",
    "        ax.set_ylabel('Cumulative frequency')\n",
    "        if len(n) == len(modlist):\n",
    "            nmin, nmax = min(n), max(n)\n",
    "            ax.text(5,0.02, '# particles: {:,} - {:,}'.format(nmin, nmax))\n",
    "        \n",
    "CS.suptitle('Comparison of glacial particle time distributions by {} for FWP scenarios'.format(category), fontsize=18)  \n",
    "CS.tight_layout()\n",
    "\n",
    "if n_uni < 18:\n",
    "    #CS.subplots_adjust(top= 0.86, hspace=0.85)\n",
    "    CS.subplots_adjust(top= 0.86)\n",
    "elif n_uni < 100:\n",
    "    CS.subplots_adjust(top= 0.93, hspace=0.55)\n",
    "elif n_uni < 400:\n",
    "    CS.subplots_adjust(top= 0.95, hspace=0.55)\n",
    "else:\n",
    "    CS.subplots_adjust(top= 0.97, hspace=0.55)\n",
    "\n",
    "dst = 'RTD_compare--{}_{}'.format(category, scenario_name)\n",
    "dst_pth = os.path.join(fig_dir, dst)\n",
    "plt.savefig(dst_pth)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 plot of Young Fraction btwn 5LhK against 1L and 5LzK models for select HUC scale.\n",
    "\n",
    "uniques = dfdict[eptlist[0]][category].unique()\n",
    "# remove any HUCs listed in purge_hucs\n",
    "for h in purge_hucs:\n",
    "    ind = np.where(uniques==h)\n",
    "    uniques = np.delete(uniques, ind)\n",
    "\n",
    "yfhucdict = {}\n",
    "yfvalues = []\n",
    "skiphuc = []\n",
    "for j, cat_val in enumerate(uniques):  # each HUC ID\n",
    "    yfmoddict = {}\n",
    "    for i, md in enumerate(eptlist):  # each of the 3 FWP models\n",
    "        #mn = modlist[i]\n",
    "        mn = eptlist[i]\n",
    "        df = dfdict[md][dfdict[md][category]==cat_val].copy()\n",
    "        if df.rt.count() >= minptl:\n",
    "            youngdf = df.loc[df.rt < age_cutoff]\n",
    "            yf = youngdf.rt.count() / df.rt.count()\n",
    "            yfmoddict[mn] = yf\n",
    "            yfvalues.append(yf)\n",
    "        else:\n",
    "            skiphuc.append(cat_val)\n",
    "            break\n",
    "    if cat_val not in skiphuc:\n",
    "        yfhucdict[cat_val] = yfmoddict    \n",
    "        \n",
    "ddd = pd.DataFrame(yfhucdict).T\n",
    "print(mean_squared_error(np.array(ddd[x1]), np.array(ddd[y1])))\n",
    "r2_y1 = r2_score(np.array(ddd[x1]), np.array(ddd[y1]))\n",
    "#r2_y2 = r2_score(np.array(ddd[x1]), np.array(ddd[y2]))\n",
    "print(r2_y1)\n",
    "#print(r2_y2)\n",
    "\n",
    "ax = ddd.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', label='1-layer zoned K')\n",
    "#ddd.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', label = '5-layer zoned K', ax=ax)\n",
    "mini, maxi = min(yfvalues), max(yfvalues)\n",
    "y1x = maxi - ((maxi-mini)/2)\n",
    "ax.plot((mini, maxi), (mini, maxi), 'k--')\n",
    "plt.xlabel('Fraction of young water (<{} yr) in the base-case model'.format(age_cutoff))\n",
    "plt.ylabel('Fraction of young water (<{} yr) in the scenario models'.format(age_cutoff))\n",
    "plt.suptitle('Comparison of glacial young fraction\\n among model scenarios by {}'.format(category), fontsize=14)\n",
    "ax.text(0.76, maxi, 'R2 = {:3.3f}'.format(r2_y1), fontsize=9, color='green')\n",
    "#ax.text(0.76, maxi-0.02, 'R2 = {:3.3f}'.format(r2_y2), fontsize=9, color='blue')\n",
    "#plt.tight_layout()\n",
    "\n",
    "dst = 'YFrac_glac_121_{}_{}'.format(category, scenario_name)\n",
    "#loc = os.path.dirname(path[modlist[0]])  # should go up one directory to the dir that houses all of the models.\n",
    "#dst_pth = os.path.join(loc, dst)\n",
    "dst_pth = os.path.join(fig_dir, dst)\n",
    "plt.savefig(dst_pth)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 plot of Young Fraction btwn 5LhK against 1L and 5LzK models for ALL HUC scales.\n",
    "\n",
    "hucs = ['HUC6', 'HUC8', 'HUC10', 'HUC12']\n",
    "nhucs = len(hucs)\n",
    "fig, [[ax1, ax2], [ax3, ax4]] = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "axisdict = {0:ax1, 1:ax2, 2:ax3, 3:ax4}\n",
    "\n",
    "for k, each in enumerate(hucs):\n",
    "    # make sure we get ALL unique HUC IDs\n",
    "    u1 = dfdict[eptlist[0]][each].unique()\n",
    "    u2 = dfdict[eptlist[1]][each].unique()\n",
    "    #u3 = dfdict[eptlist[2]][each].unique()\n",
    "    u = np.append(u1, u2)\n",
    "    #u = np.append(u, u3)\n",
    "    uniques = np.unique(u)\n",
    "    # remove any HUCs listed in purge_hucs\n",
    "    for h in purge_hucs:\n",
    "        ind = np.where(uniques==h)\n",
    "        uniques = np.delete(uniques, ind)\n",
    "    axis = axisdict[k]\n",
    "\n",
    "    yfhucdict = {}\n",
    "    yfvalues = []\n",
    "    skiphuc = []\n",
    "    for j, cat_val in enumerate(uniques):  # each HUC ID\n",
    "        yfmoddict = {}\n",
    "        for i, md in enumerate(eptlist):  # each of the 3 FWP models\n",
    "            mn = eptlist[i]\n",
    "            df = dfdict[md].loc[dfdict[md][each]==cat_val]\n",
    "            if df.rt.count() >= minptl:\n",
    "                youngdf = df.loc[df.rt < age_cutoff]\n",
    "                yf = youngdf.rt.count() / df.rt.count()\n",
    "                yfmoddict[mn] = yf\n",
    "                yfvalues.append(yf)\n",
    "            else:\n",
    "                skiphuc.append(cat_val)\n",
    "                break\n",
    "        if cat_val not in skiphuc:\n",
    "            yfhucdict[cat_val] = yfmoddict    \n",
    "\n",
    "    ddd = pd.DataFrame(yfhucdict).T\n",
    "    r2_y1 = r2_score(np.array(ddd[x1]), np.array(ddd[y1]))\n",
    "    #r2_y2 = r2_score(np.array(ddd[x1]), np.array(ddd[y2]))\n",
    "    \n",
    "    #plotting\n",
    "    mini, maxi = min(yfvalues), max(yfvalues)\n",
    "    #xplot = mini+(maxi-mini)/2\n",
    "    yrange = maxi-mini\n",
    "    if k == 0:\n",
    "        ddd.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', label='1-layer zoned K', ax=axis)\n",
    "        #ddd.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', label = '5-layer zoned K', ax=axis)\n",
    "        axis.text(mini, mini+0.83*yrange, 'R2 = {:3.3f}'.format(r2_y1), fontsize=9, color='green')\n",
    "        #axis.text(mini, mini+0.78*yrange, 'R2 = {:3.3f}'.format(r2_y2), fontsize=9, color='blue')\n",
    "    else:\n",
    "        ddd.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', ax=axis)\n",
    "        #ddd.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', ax=axis)\n",
    "        axis.text(mini, mini+yrange, 'R2 = {:3.3f}'.format(r2_y1), fontsize=9, color='green')\n",
    "        #axis.text(mini, mini+0.95*yrange, 'R2 = {:3.3f}'.format(r2_y2), fontsize=9, color='blue')\n",
    "    \n",
    "    axis.plot((mini, maxi), (mini, maxi), 'k--')\n",
    "    axis.set_xlabel(''), axis.set_ylabel('')\n",
    "    axis.set_title(each)\n",
    "    \n",
    "    # Add an attribute to the HUC shapefile\n",
    "    shapefile = HUCshpdict[each]\n",
    "    shp = gpd.read_file(shapefile)  \n",
    "    shp[each] = shp[each].astype('int64')  # convert so can merge\n",
    "    ddd.index = ddd.index.astype('int64')  # convert so can merge\n",
    "    ddd['YF_{}-{}'.format(scenario_name, base_case)] = ddd[x1] - ddd[y1]\n",
    "    #ddd['YF_hK-zK'] = ddd[x1] - ddd[y2]\n",
    "\n",
    "    df = pd.merge(shp, ddd, how='outer', left_on=each, right_index=True)\n",
    "    dst = shapefile[:-4] + '_YF_{}.shp'.format(scenario_name)\n",
    "    df.to_file(dst)\n",
    "\n",
    "fig.text(0.5, 0.06, 'Fraction of young water (<{} yr) in the base model'.format(age_cutoff), ha='center')\n",
    "fig.text(0.06, 0.48, 'Fraction of young water (<{} yr) in the scenario model'.format(age_cutoff), va='center', rotation='vertical')\n",
    "plt.subplots_adjust(top = .9)\n",
    "fig.suptitle('Comparison of glacial aquifer\\n young fractions by HUCs for scenario \"{}\"'.format(scenario_name), fontsize=14)\n",
    "\n",
    "dst = 'YFrac_glac_121_allHUCs_{}'.format(scenario_name)\n",
    "#loc = os.path.dirname(path[modlist[0]])  # go up one directory to the dir that houses all of the models.\n",
    "#dst_pth = os.path.join(loc, dst)\n",
    "dst_pth = os.path.join(fig_dir, dst)\n",
    "plt.savefig(dst_pth)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 plot of meanYoungAge and meanOldAge btwn 5LhK against 1L and 5LzK models for select HUC scale.\n",
    "\n",
    "# make sure we get ALL unique HUC IDs\n",
    "u1 = dfdict[eptlist[0]][category].unique()\n",
    "u2 = dfdict[eptlist[1]][category].unique()\n",
    "#u3 = dfdict[eptlist[2]][category].unique()\n",
    "u = np.append(u1, u2)\n",
    "#u = np.append(u, u3)\n",
    "uniques = np.unique(u)\n",
    "# remove any HUCs listed in purge_hucs\n",
    "for h in purge_hucs:\n",
    "    ind = np.where(uniques==h)\n",
    "    uniques = np.delete(uniques, ind)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10, 4.6))\n",
    "\n",
    "skiphuc = []\n",
    "yfhucdict = {}\n",
    "yfvalues = []\n",
    "ofhucdict = {}\n",
    "ofvalues = []\n",
    "for j, cat_val in enumerate(uniques):  # each HUC ID\n",
    "    yfmoddict = {}\n",
    "    ofmoddict = {}\n",
    "    for i, md in enumerate(eptlist):  # each of the 3 FWP models\n",
    "        mn = eptlist[i]\n",
    "        df = dfdict[md].loc[dfdict[md][category]==cat_val]\n",
    "        if df.rt.count() >= minptl:\n",
    "            youngdf = df.loc[df.rt < age_cutoff]\n",
    "            olddf = df.loc[df.rt >= age_cutoff]\n",
    "            yfage = youngdf.rt.median()\n",
    "            ofage = olddf.rt.median()\n",
    "            yfmoddict[mn] = yfage\n",
    "            yfvalues.append(yfage) \n",
    "            ofmoddict[mn] = ofage\n",
    "            ofvalues.append(ofage)\n",
    "        else:\n",
    "            skiphuc.append(cat_val)\n",
    "            break\n",
    "    if cat_val not in skiphuc:\n",
    "        yfhucdict[cat_val] = yfmoddict\n",
    "        ofhucdict[cat_val] = ofmoddict\n",
    "        \n",
    "young = pd.DataFrame(yfhucdict).T\n",
    "old = pd.DataFrame(ofhucdict).T\n",
    "young.dropna(axis='index', how='any', inplace=True)\n",
    "old.dropna(axis='index', how='any', inplace=True)\n",
    "r2_y1y = r2_score(np.array(young[x1]), np.array(young[y1]))\n",
    "#r2_y2y = r2_score(np.array(young[x1]), np.array(young[y2]))\n",
    "r2_y1o = r2_score(np.array(old[x1]), np.array(old[y1]))\n",
    "#r2_y2o = r2_score(np.array(old[x1]), np.array(old[y2]))\n",
    "\n",
    "#plotting\n",
    "miny, maxy = min(yfvalues), max(yfvalues)\n",
    "mino, maxo = min(ofvalues), max(ofvalues)\n",
    "xplot = mini+(maxi-mini)/2\n",
    "yrange_y = maxy-miny\n",
    "yrange_o = maxo-mino\n",
    "\n",
    "young.plot(kind='scatter', x=x1, y=y1, marker='o', c='green', label='1-layer zoned K', ax=ax1)\n",
    "#young.plot(kind='scatter', x=x1, y=y2, marker='^', c='blue', label='5-layer zoned K', ax=ax1)\n",
    "old.plot(kind='scatter', x=x1, y=y1, marker='o', c='green', ax=ax2)\n",
    "#old.plot(kind='scatter', x=x1, y=y2, marker='^', c='blue', ax=ax2)\n",
    "ax1.text(miny, miny+0.80*yrange_y, 'R2 = {:3.3f}'.format(r2_y1y), fontsize=9, color='green')\n",
    "#ax1.text(miny, miny+0.75*yrange_y, 'R2 = {:3.3f}'.format(r2_y2y), fontsize=9, color='blue')\n",
    "ax2.text(mino, mino+yrange_o, 'R2 = {:3.3f}'.format(r2_y1o), fontsize=9, color='green')\n",
    "#ax2.text(mino, mino+0.95*yrange_o, 'R2 = {:3.3f}'.format(r2_y2o), fontsize=9, color='blue')\n",
    "ax1.plot((miny, maxy), (miny, maxy), 'k--')\n",
    "ax2.plot((mino, maxo), (mino, maxo), 'k--')\n",
    "ax1.set_xlabel(''), ax1.set_ylabel(''), ax2.set_ylabel(''), ax2.set_xlabel('')\n",
    "fig.text(0.25, 0.82, 'Young fraction')\n",
    "fig.text(0.73, 0.82, 'Old fraction', ha='center')\n",
    "fig.text(0.07, 0.45, 'Median age (yrs) for the scenario model', va='center', rotation='vertical')\n",
    "fig.text(0.5, 0.01, 'Median age (yrs) for the base model', ha='center')\n",
    "plt.subplots_adjust(top = .8)\n",
    "fig.suptitle('Comparison of median ages for young and\\n old water in the glacial aquifer by {} for scenario {}'.format(category, scenario_name), fontsize=14)\n",
    "#fig.tight_layout()\n",
    "\n",
    "dst = 'YnOages_121_{}_{}'.format(category, scenario_name)\n",
    "#loc = os.path.dirname(path[modlist[0]])  # should go up one directory to the dir that houses all of the models.\n",
    "#dst_pth = os.path.join(loc, dst)\n",
    "dst_pth = os.path.join(fig_dir, dst)\n",
    "plt.savefig(dst_pth)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 plot of meanYoungAge and meanOldAge btwn 5LhK against 1L and 5LzK models for ALL HUC scales.\n",
    "\n",
    "# Better viewed as separate plots via code block below\n",
    "'''\n",
    "hucs = ['HUC6', 'HUC8', 'HUC10', 'HUC12']\n",
    "nhucs = len(hucs)\n",
    "fig, [[ax1, ax2, ax3, ax4], [ax5, ax6, ax7, ax8]] = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))\n",
    "youngaxisdict = {0:ax1, 1:ax2, 2:ax5, 3:ax6}\n",
    "oldaxisdict = {0:ax3, 1:ax4, 2:ax7, 3:ax8}\n",
    "\n",
    "for k, each in enumerate(hucs):\n",
    "    # make sure we get ALL unique HUC IDs\n",
    "    u1 = dfdict[eptlist[0]][each].unique()\n",
    "    u2 = dfdict[eptlist[1]][each].unique()\n",
    "    u3 = dfdict[eptlist[2]][each].unique()\n",
    "    u = np.append(u1, u2)\n",
    "    u = np.append(u, u3)\n",
    "    uniques = np.unique(u)\n",
    "    # remove any HUCs listed in purge_hucs\n",
    "    for h in purge_hucs:\n",
    "        ind = np.where(uniques==h)\n",
    "        uniques = np.delete(uniques, ind)\n",
    "    youngaxis = youngaxisdict[k]\n",
    "    oldaxis = oldaxisdict[k]\n",
    "    ofhucdict = {}\n",
    "    yfhucdict = {}\n",
    "    yfvalues = []\n",
    "    ofvalues = []\n",
    "    skiphuc = []\n",
    "    for j, cat_val in enumerate(uniques):  # each HUC ID\n",
    "        yfmoddict = {} \n",
    "        ofmoddict = {} \n",
    "        for i, md in enumerate(eptlist):  # each of the 3 FWP models\n",
    "            mn = modlist[i]\n",
    "            df = dfdict[md].loc[dfdict[md][each]==cat_val]\n",
    "            if df.rt.count() >= minptl:\n",
    "                youngdf = df.loc[df.rt < age_cutoff]\n",
    "                olddf = df.loc[df.rt >= age_cutoff]\n",
    "                yfage = youngdf.rt.median()\n",
    "                ofage = olddf.rt.median()\n",
    "                yfmoddict[mn] = yfage\n",
    "                yfvalues.append(yfage) \n",
    "                ofmoddict[mn] = ofage\n",
    "                ofvalues.append(ofage)\n",
    "                # pull out raw time info for generalized model areas for later use...\n",
    "                if (cat_val == float(genHUCdict['Oconto'])) and ('fwp5lzk' in mn):  # 5lzK is the most similar to Generalized models\n",
    "                    FWPzKocontoDF = df.copy()\n",
    "                #elif cat_val == float(genHUCdict['TWR'])  and (md == 'fwp5lzk'):\n",
    "                elif cat_val == float(genHUCdict['TWR'])  and ('fwp5lzk' in mn):\n",
    "                    FWPzKtwrDF = df.copy()\n",
    "                elif (cat_val == float(genHUCdict['Oconto'])) and ('fwp5lhk' in mn):  # 5lzK is the most similar to Generalized models\n",
    "                    FWPhKocontoDF = df.copy()\n",
    "                elif cat_val == float(genHUCdict['TWR'])  and ('fwp5lhk' in mn):\n",
    "                    FWPhKtwrDF = df.copy()\n",
    "                elif (cat_val == float(genHUCdict['Oconto'])) and ('fwp1l' in mn):  # 5lzK is the most similar to Generalized models\n",
    "                    FWP1locontoDF = df.copy()\n",
    "                elif cat_val == float(genHUCdict['TWR'])  and ('fwp1l' in mn):\n",
    "                    FWP1ltwrDF = df.copy()                    \n",
    "            else:\n",
    "                skiphuc.append(cat_val)\n",
    "                break\n",
    "        if cat_val not in skiphuc:\n",
    "            yfhucdict[cat_val] = yfmoddict\n",
    "            ofhucdict[cat_val] = ofmoddict            \n",
    "            \n",
    "    young = pd.DataFrame(yfhucdict).T\n",
    "    old = pd.DataFrame(ofhucdict).T\n",
    "    for n in modlist:\n",
    "        young = young.loc[~young[n].isnull()]  # need to remove any NANs\n",
    "        old = old.loc[~old[n].isnull()]  # need to remove any NANs\n",
    "    r2_y1y = r2_score(np.array(young[x1]), np.array(young[y1]))\n",
    "    r2_y2y = r2_score(np.array(young[x1]), np.array(young[y2]))\n",
    "    r2_y1o = r2_score(np.array(old[x1]), np.array(old[y1]))\n",
    "    r2_y2o = r2_score(np.array(old[x1]), np.array(old[y2]))\n",
    "    \n",
    "    #plotting\n",
    "    miny, maxy = min(yfvalues), max(yfvalues)\n",
    "    mino, maxo = min(ofvalues), max(ofvalues)\n",
    "    #xplot = mini+(maxi-mini)/2\n",
    "    yrange_y = maxy-miny\n",
    "    yrange_o = maxo-mino\n",
    "    \n",
    "    if k == 0:\n",
    "        young.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', label='1-layer zoned K', ax=youngaxis)\n",
    "        young.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', label = '5-layer zoned K', ax=youngaxis)        \n",
    "        old.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', ax=oldaxis)\n",
    "        old.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', ax=oldaxis)  \n",
    "    else:\n",
    "        young.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', ax=youngaxis)\n",
    "        young.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', ax=youngaxis)\n",
    "        old.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', ax=oldaxis)\n",
    "        old.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', ax=oldaxis)  \n",
    "        \n",
    "    youngaxis.text(miny, miny+yrange_y, 'R2 = {:3.3f}'.format(r2_y1y), fontsize=9, color='green')\n",
    "    youngaxis.text(miny, miny+0.95*yrange_y, 'R2 = {:3.3f}'.format(r2_y2y), fontsize=9, color='blue')\n",
    "    oldaxis.text(mino, mino+yrange_o, 'R2 = {:3.3f}'.format(r2_y1o), fontsize=9, color='green')\n",
    "    oldaxis.text(mino, mino+0.95*yrange_o, 'R2 = {:3.3f}'.format(r2_y2o), fontsize=9, color='blue')\n",
    "    youngaxis.plot((miny, maxy), (miny, maxy), 'k--')\n",
    "    oldaxis.plot((mino, maxo), (mino, maxo), 'k--')\n",
    "\n",
    "    youngaxis.set_xlabel(''), youngaxis.set_ylabel(''), oldaxis.set_xlabel(''), oldaxis.set_ylabel('')\n",
    "    youngaxis.set_title(each)\n",
    "    oldaxis.set_title(each)\n",
    "    \n",
    "    # Add an attribute to the HUC shapefile\n",
    "    shapefile = HUCshpdict[each]\n",
    "    shp = gpd.read_file(shapefile)  \n",
    "    shp[each] = shp[each].astype('int64')  # convert so can merge\n",
    "    \n",
    "    young.index = young.index.astype('int64')  # convert so can merge\n",
    "    young['mYage_hK-1L'] = young[x1] - young[y1]\n",
    "    young['mYage_hK-zK'] = young[x1] - young[y2]\n",
    "    df = pd.merge(shp, young, how='outer', left_on=each, right_index=True)\n",
    "    dst = shapefile[:-4] + '_mYage.shp'\n",
    "    df.to_file(dst)\n",
    "    \n",
    "    old.index = old.index.astype('int64')  # convert so can merge\n",
    "    old['mOage_hK-1L'] = old[x1] - old[y1]\n",
    "    old['mOage_hK-zK'] = old[x1] - old[y2]\n",
    "    dfo = pd.merge(shp, old, how='outer', left_on=each, right_index=True)\n",
    "    dsto = shapefile[:-4] + '_mOage.shp'\n",
    "    dfo.to_file(dsto)\n",
    "\n",
    "fig.text(0.28, 0.92, 'Young fraction', fontsize=12)\n",
    "fig.text(0.71, 0.92, 'Old fraction', ha='center', fontsize=12)\n",
    "fig.text(0.5, 0.055, 'Median age (yrs) for the complex model', ha='center', fontsize=12)\n",
    "fig.text(0.095, 0.48, 'Median age (yrs) for the simpler models', va='center', fontsize=12, rotation='vertical')\n",
    "plt.subplots_adjust(top = .89)\n",
    "fig.suptitle('Comparison of median ages for young and old water in the glacial aquifer by HUCs', fontsize=16)\n",
    "\n",
    "# add background color\n",
    "youngrect = patches.Rectangle((200,70), 760, 830, zorder=-1, alpha=0.5, facecolor='b')\n",
    "oldrect = patches.Rectangle((960,70), 780, 830, zorder=-1, alpha=0.5, facecolor='r')\n",
    "fig.patches.append(youngrect)\n",
    "fig.patches.append(oldrect)\n",
    "\n",
    "dst = 'YnOages_121_allHUCs'\n",
    "#loc = os.path.dirname(path[modlist[0]])  # go up one directory to the dir that houses all of the models.\n",
    "#dst_pth = os.path.join(loc, dst)\n",
    "dst_pth = os.path.join(fig_dir, dst)\n",
    "plt.savefig(dst_pth)\n",
    "#plt.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1:1 plot of meanYoungAge and meanOldAge btwn 5LhK against 1L and 5LzK models for ALL HUC scales.\n",
    "\n",
    "hucs = ['HUC6', 'HUC8', 'HUC10', 'HUC12']\n",
    "nhucs = len(hucs)\n",
    "fig1, [[ax1, ax2], [ax3, ax4]] = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "fig2, [[ax5, ax6], [ax7, ax8]] = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "youngaxisdict = {0:ax1, 1:ax2, 2:ax3, 3:ax4}\n",
    "oldaxisdict = {0:ax5, 1:ax6, 2:ax7, 3:ax8}\n",
    "\n",
    "for k, each in enumerate(hucs):\n",
    "    # make sure we get ALL unique HUC IDs\n",
    "    u1 = dfdict[eptlist[0]][each].unique()\n",
    "    u2 = dfdict[eptlist[1]][each].unique()\n",
    "    #u3 = dfdict[eptlist[2]][each].unique()\n",
    "    u = np.append(u1, u2)\n",
    "    #u = np.append(u, u3)\n",
    "    uniques = np.unique(u)\n",
    "    # remove any HUCs listed in purge_hucs\n",
    "    for h in purge_hucs:\n",
    "        ind = np.where(uniques==h)\n",
    "        uniques = np.delete(uniques, ind)\n",
    "    youngaxis = youngaxisdict[k]\n",
    "    oldaxis = oldaxisdict[k]\n",
    "    ofhucdict = {}\n",
    "    yfhucdict = {}\n",
    "    yfvalues = []\n",
    "    ofvalues = []\n",
    "    skiphuc = []\n",
    "    for j, cat_val in enumerate(uniques):  # each HUC ID\n",
    "        yfmoddict = {} \n",
    "        ofmoddict = {} \n",
    "        for i, md in enumerate(eptlist):  # each of the 3 FWP models\n",
    "            mn = eptlist[i]\n",
    "            df = dfdict[md].loc[dfdict[md][each]==cat_val]\n",
    "            if df.rt.count() >= minptl:\n",
    "                youngdf = df.loc[df.rt < age_cutoff]\n",
    "                olddf = df.loc[df.rt >= age_cutoff]\n",
    "                yfage = youngdf.rt.median()\n",
    "                ofage = olddf.rt.median()\n",
    "                yfmoddict[mn] = yfage\n",
    "                yfvalues.append(yfage) \n",
    "                ofmoddict[mn] = ofage\n",
    "                ofvalues.append(ofage)\n",
    "                # pull out raw time info for generalized model areas for later use...\n",
    "                if (cat_val == float(genHUCdict['Oconto'])) and ('fwp5lzk' in mn):  # 5lzK is the most similar to Generalized models\n",
    "                    FWPzKocontoDF = df.copy()\n",
    "                #elif cat_val == float(genHUCdict['TWR'])  and (md == 'fwp5lzk'):\n",
    "                elif cat_val == float(genHUCdict['TWR'])  and ('fwp5lzk' in mn):\n",
    "                    FWPzKtwrDF = df.copy()\n",
    "                elif (cat_val == float(genHUCdict['Oconto'])) and ('fwp5lhk' in mn):  # 5lzK is the most similar to Generalized models\n",
    "                    FWPhKocontoDF = df.copy()\n",
    "                elif cat_val == float(genHUCdict['TWR'])  and ('fwp5lhk' in mn):\n",
    "                    FWPhKtwrDF = df.copy()\n",
    "                elif (cat_val == float(genHUCdict['Oconto'])) and ('fwp1l' in mn):  # 5lzK is the most similar to Generalized models\n",
    "                    FWP1locontoDF = df.copy()\n",
    "                elif cat_val == float(genHUCdict['TWR'])  and ('fwp1l' in mn):\n",
    "                    FWP1ltwrDF = df.copy()                    \n",
    "            else:\n",
    "                skiphuc.append(cat_val)\n",
    "                break\n",
    "        if cat_val not in skiphuc:\n",
    "            yfhucdict[cat_val] = yfmoddict\n",
    "            ofhucdict[cat_val] = ofmoddict            \n",
    "            \n",
    "    young = pd.DataFrame(yfhucdict).T\n",
    "    old = pd.DataFrame(ofhucdict).T\n",
    "    young.dropna(axis='index', how='any', inplace=True)  # better way to remove NANs\n",
    "    old.dropna(axis='index', how='any', inplace=True)\n",
    "    #for n in modlist:\n",
    "    #    young = young.loc[~young[n].isnull()]  # need to remove any NANs\n",
    "    #    old = old.loc[~old[n].isnull()]  # need to remove any NANs\n",
    "    r2_y1y = r2_score(np.array(young[x1]), np.array(young[y1]))\n",
    "    #r2_y2y = r2_score(np.array(young[x1]), np.array(young[y2]))\n",
    "    r2_y1o = r2_score(np.array(old[x1]), np.array(old[y1]))\n",
    "    #r2_y2o = r2_score(np.array(old[x1]), np.array(old[y2]))\n",
    "    \n",
    "    #plotting\n",
    "    miny, maxy = min(yfvalues), max(yfvalues)\n",
    "    mino, maxo = min(ofvalues), max(ofvalues)\n",
    "    #xplot = mini+(maxi-mini)/2\n",
    "    yrange_y = maxy-miny\n",
    "    yrange_o = maxo-mino\n",
    "    \n",
    "    if k == 0:\n",
    "        young.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', label='1-layer zoned K', ax=youngaxis)\n",
    "        #young.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', label = '5-layer zoned K', ax=youngaxis)        \n",
    "        old.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', label='1-layer zoned K', ax=oldaxis)\n",
    "        #old.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', label = '5-layer zoned K', ax=oldaxis)  \n",
    "        #ax1.text(miny, miny+0.80*yrange_y, 'R2 = {:3.3f}'.format(r2_y1y), fontsize=9, color='green')\n",
    "        #ax1.text(miny, miny+0.75*yrange_y, 'R2 = {:3.3f}'.format(r2_y2y), fontsize=9, color='blue')\n",
    "        #ax5.text(miny, miny+0.80*yrange_y, 'R2 = {:3.3f}'.format(r2_y1y), fontsize=9, color='green')\n",
    "        #ax5.text(miny, miny+0.75*yrange_y, 'R2 = {:3.3f}'.format(r2_y2y), fontsize=9, color='blue')\n",
    "        youngaxis.text(miny, miny+0.83*yrange_y, 'R2 = {:3.3f}'.format(r2_y1y), fontsize=9, color='green')\n",
    "        #youngaxis.text(miny, miny+0.78*yrange_y, 'R2 = {:3.3f}'.format(r2_y2y), fontsize=9, color='blue')\n",
    "        oldaxis.text(mino, mino+0.83*yrange_o, 'R2 = {:3.3f}'.format(r2_y1o), fontsize=9, color='green')\n",
    "        #oldaxis.text(mino, mino+0.78*yrange_o, 'R2 = {:3.3f}'.format(r2_y2o), fontsize=9, color='blue')\n",
    "    else:\n",
    "        young.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', ax=youngaxis)\n",
    "        #young.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', ax=youngaxis)\n",
    "        old.plot(kind='scatter', x=x1, y=y1, marker='o', color='green', ax=oldaxis)\n",
    "        #old.plot(kind='scatter', x=x1, y=y2, marker='^', color='blue', ax=oldaxis)     \n",
    "        youngaxis.text(miny, miny+yrange_y, 'R2 = {:3.3f}'.format(r2_y1y), fontsize=9, color='green')\n",
    "        #youngaxis.text(miny, miny+0.95*yrange_y, 'R2 = {:3.3f}'.format(r2_y2y), fontsize=9, color='blue')\n",
    "        oldaxis.text(mino, mino+yrange_o, 'R2 = {:3.3f}'.format(r2_y1o), fontsize=9, color='green')\n",
    "        #oldaxis.text(mino, mino+0.95*yrange_o, 'R2 = {:3.3f}'.format(r2_y2o), fontsize=9, color='blue')\n",
    "        \n",
    "    youngaxis.plot((miny, maxy), (miny, maxy), 'k--')\n",
    "    oldaxis.plot((mino, maxo), (mino, maxo), 'k--')\n",
    "\n",
    "    youngaxis.set_xlabel(''), youngaxis.set_ylabel(''), oldaxis.set_xlabel(''), oldaxis.set_ylabel('')\n",
    "    youngaxis.set_title(each)\n",
    "    oldaxis.set_title(each)\n",
    "    \n",
    "    # Add an attribute to the HUC shapefile\n",
    "    shapefile = HUCshpdict[each]\n",
    "    shp = gpd.read_file(shapefile)  \n",
    "    shp[each] = shp[each].astype('int64')  # convert so can merge\n",
    "    \n",
    "    young.index = young.index.astype('int64')  # convert so can merge\n",
    "    young['mYage_{}-{}'.format(scenario_name, base_case)] = young[x1] - young[y1]\n",
    "    #young['mYage_hK-zK'] = young[x1] - young[y2]\n",
    "    df = pd.merge(shp, young, how='outer', left_on=each, right_index=True)\n",
    "    dst = shapefile[:-4] + '_mYage_{}.shp'.format(scenario_name)\n",
    "    df.to_file(dst)\n",
    "    \n",
    "    old.index = old.index.astype('int64')  # convert so can merge\n",
    "    old['mOage_{}-{}'.format(scenario_name, base_case)] = old[x1] - old[y1]\n",
    "    #old['mOage_hK-zK'] = old[x1] - old[y2]\n",
    "    dfo = pd.merge(shp, old, how='outer', left_on=each, right_index=True)\n",
    "    dsto = shapefile[:-4] + '_mOage_{}.shp'.format(scenario_name)\n",
    "    dfo.to_file(dsto)\n",
    "\n",
    "fig1.text(0.46, 0.92, 'Young fraction', fontsize=12)\n",
    "#fig.text(0.71, 0.92, 'Old fraction', ha='center', fontsize=12)\n",
    "fig2.text(0.48, 0.92, 'Old fraction', fontsize=12)\n",
    "fig1.text(0.5, 0.055, 'Median age (yrs) for the base model', ha='center', fontsize=12)\n",
    "fig1.text(0.001, 0.48, 'Median age (yrs) for the scenario model', va='center', fontsize=12, rotation='vertical')\n",
    "fig2.text(0.5, 0.055, 'Median age (yrs) for the base model', ha='center', fontsize=12)\n",
    "fig2.text(0.005, 0.48, 'Median age (yrs) for the scenario models', va='center', fontsize=12, rotation='vertical')\n",
    "plt.subplots_adjust(top = .89)\n",
    "fig1.suptitle('Comparison of median ages for young fraction in the glacial aquifer by HUCs for scenario {}'.format(scenario_name), fontsize=16)\n",
    "fig2.suptitle('Comparison of median ages for old fraction in the glacial aquifer by HUCs for scenario {}'.format(scenario_name), fontsize=16)\n",
    "\n",
    "# add background color\n",
    "#youngrect = patches.Rectangle((200,70), 760, 830, zorder=-1, alpha=0.5, facecolor='b')\n",
    "#oldrect = patches.Rectangle((960,70), 780, 830, zorder=-1, alpha=0.5, facecolor='r')\n",
    "#fig.patches.append(youngrect)\n",
    "#fig.patches.append(oldrect)\n",
    "\n",
    "dst1 = 'Yages_121_allHUCs_{}'.format(scenario_name)\n",
    "dst2 = 'Oages_121_allHUCs_{}'.format(scenario_name)\n",
    "#loc = os.path.dirname(path[modlist[0]])  # go up one directory to the dir that houses all of the models.\n",
    "#dst_pth = os.path.join(loc, dst)\n",
    "dst_pth1 = os.path.join(fig_dir, dst1)\n",
    "dst_pth2 = os.path.join(fig_dir, dst2)\n",
    "fig1.savefig(dst_pth1)\n",
    "fig2.savefig(dst_pth2)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
